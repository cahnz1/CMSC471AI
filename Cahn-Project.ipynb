{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC471 Artificial Intelligence\n",
    "\n",
    "# Project Final Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Title: Video Game Sales with Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zippy Cahn ID: ER57013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "- Specify exactly what ML approach your problem is: Binary classification, multi-class classification, or regression (groups should work on two approaches).\n",
    "\n",
    "This is a multi-class classification problem. I plan on using all of the features to try and perdict the ESRB rating (final collum) for video games.  \n",
    "\n",
    "\n",
    "- Then, explain the problem further. Be clear and concise.\n",
    "\n",
    "The problem is trying to classify a game's ESRB rating using their different features.  This may help companies determine which kind of game they should devlope and what their rival companies are developing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Explain briefly why this problem is important and how you became interested in it. You may use the motivation from the proposal.\n",
    "\n",
    "I am currently trying to get into the gaming industry and this interests me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "- Link to dataset source: https://www.kaggle.com/rush4ratio/video-game-sales-with-ratings\n",
    "\n",
    "- <b>Label/target</b> description - What column in your dataset you are trying to predict? Specify exactly what your target feature (label) is. It must be one of the dataset columns. For image classification, specify your class labels.\n",
    "\n",
    "The target is to predict a game's rating.  I will be using all the features except the name feature to accomplish this.\n",
    "\n",
    "- Feature description: briefly explain each of the features/columns.\n",
    "\n",
    "\n",
    "- Platform: What console/platform the game is one. \n",
    "- Year_of_release: The year the game was released.\n",
    "- Genre: The game's genre.\n",
    "- Publisher: the company who created the game.\n",
    "- NA_Sales: North America sales.\n",
    "- EU_Sales: Europe sales.\n",
    "- JP_Sales: Japan sales.\n",
    "- other_Sales: Other countries sales.\n",
    "- Global_Sales: All sales.\n",
    "- Critic_score: Aggregate score compiled by Metacritic staff.\n",
    "- Critic_count: The number of critics used in coming up with the Critic_score.\n",
    "- User_score: Score by Metacritic's subscribers.\n",
    "- User_count: Number of users who gave the user_score.\n",
    "- Developer: Party responsible for creating the game.\n",
    "- Rating: The ESRB ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Include the code for loading, showing the data head (if loaded with pandas) and reporting the data shape via sklearn, pandas or tensorflow in the following cell. \n",
    "\n",
    "\n",
    "- For image classification or special non-pandas datasets, show at least one sample of the data.\n",
    "\n",
    "\n",
    "- <b>Your data should be loaded error-free (otherwise your whole project gets zero credit). You should attach the data to your final project submission in a zip file.</b> If your dataset is too large and can't be uploaded in Blackboard, you should email the dataset to the instructor BEFORE the deadline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Python, sklearn and/or tensorflow/keras modules for loading the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load the data\n",
    "\n",
    "game_data = pd.read_csv('video.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Print data shape via built-in methods of sklearn, pandas or tensorflow/keras (or other modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf Version:  2.0.0\n",
      "Eager Execution mode:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"tf Version: \", tf.__version__)\n",
    "print(\"Eager Execution mode: \", tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16719, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name Platform  Year_of_Release         Genre Publisher  \\\n",
       "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
       "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
       "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
       "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
       "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "1     29.08      3.58      6.81         0.77         40.24           NaN   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "4     11.27      8.89     10.22         1.00         31.37           NaN   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "1           NaN        NaN         NaN       NaN    NaN  \n",
       "2          73.0        8.3       709.0  Nintendo      E  \n",
       "3          73.0          8       192.0  Nintendo      E  \n",
       "4           NaN        NaN         NaN       NaN    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the data head (if pandas is used)\n",
    "# If the dataset contains images or is non-pandas/non-tabular, show at least one sample of the data\n",
    "# Get data shape via built-in methods of sklearn, pandas or tensorflow/keras\n",
    "print(game_data.shape)\n",
    "game_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List any steps you have taken for preprocessing, such as cleaning, dropping NAs, dropping any redundant/irrelevant column, normalizing/scaling, etc. HERE:\n",
    "\n",
    "- Preprocessing Steps:  I droped the NAs and the names collum.  I also converted the objects to to ints.  I also normalized them.  I then split the data with a 0.2 test size.  \n",
    "<br>\n",
    "\n",
    "- Specify the details of data splitting to train/test or cross validation. Mention the ratio for splitting and number of folds for cv.\n",
    "<br>\n",
    "\n",
    "I changed it from 0.2 to 0.33 which gave better results.\n",
    "\n",
    "<b>Notice:</b> Each dataset may or may not need specific preprocessing steps. You should decide which preprocessing steps (if any) is required for your particular dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary preprocessing modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Super Mario Bros.</td>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wii Play</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Half-Life</td>\n",
       "      <td>PC</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>Vivendi Games</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.12</td>\n",
       "      <td>96.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>3161.0</td>\n",
       "      <td>Valve Software</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>World of Warcraft: The Burning Crusade</td>\n",
       "      <td>PC</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Activision</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.09</td>\n",
       "      <td>91.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>785.0</td>\n",
       "      <td>Blizzard Entertainment</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Battlefield 1</td>\n",
       "      <td>PS4</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>Electronic Arts</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4.08</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>809.0</td>\n",
       "      <td>EA DICE</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>God of War II</td>\n",
       "      <td>PS2</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>Sony Computer Entertainment</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.07</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>709.0</td>\n",
       "      <td>SCE Santa Monica</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Fallout: New Vegas</td>\n",
       "      <td>X360</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Bethesda Softworks</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>4.05</td>\n",
       "      <td>84.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>769.0</td>\n",
       "      <td>Obsidian Entertainment</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name Platform  Year_of_Release  \\\n",
       "0                                Wii Sports      Wii           2006.0   \n",
       "2                            Mario Kart Wii      Wii           2008.0   \n",
       "3                         Wii Sports Resort      Wii           2009.0   \n",
       "6                     New Super Mario Bros.       DS           2006.0   \n",
       "7                                  Wii Play      Wii           2006.0   \n",
       "..                                      ...      ...              ...   \n",
       "284                               Half-Life       PC           1997.0   \n",
       "288  World of Warcraft: The Burning Crusade       PC           2007.0   \n",
       "289                           Battlefield 1      PS4           2016.0   \n",
       "290                           God of War II      PS2           2007.0   \n",
       "292                      Fallout: New Vegas     X360           2010.0   \n",
       "\n",
       "            Genre                    Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
       "0          Sports                     Nintendo     41.36     28.96      3.77   \n",
       "2          Racing                     Nintendo     15.68     12.76      3.79   \n",
       "3          Sports                     Nintendo     15.61     10.93      3.28   \n",
       "6        Platform                     Nintendo     11.28      9.14      6.50   \n",
       "7            Misc                     Nintendo     13.96      9.18      2.93   \n",
       "..            ...                          ...       ...       ...       ...   \n",
       "284       Shooter                Vivendi Games      4.03      0.00      0.09   \n",
       "288  Role-Playing                   Activision      2.57      1.52      0.00   \n",
       "289       Shooter              Electronic Arts      1.10      2.15      0.21   \n",
       "290        Action  Sony Computer Entertainment      2.32      0.04      0.04   \n",
       "292  Role-Playing           Bethesda Softworks      2.66      1.03      0.04   \n",
       "\n",
       "     Other_Sales  Global_Sales  Critic_Score  Critic_Count User_Score  \\\n",
       "0           8.45         82.53          76.0          51.0          8   \n",
       "2           3.29         35.52          82.0          73.0        8.3   \n",
       "3           2.95         32.77          80.0          73.0          8   \n",
       "6           2.88         29.80          89.0          65.0        8.5   \n",
       "7           2.84         28.92          58.0          41.0        6.6   \n",
       "..           ...           ...           ...           ...        ...   \n",
       "284         0.00          4.12          96.0          24.0        9.1   \n",
       "288         0.00          4.09          91.0          46.0        7.9   \n",
       "289         0.61          4.08          88.0          31.0        8.4   \n",
       "290         1.67          4.07          93.0          70.0        8.9   \n",
       "292         0.33          4.05          84.0          81.0        8.1   \n",
       "\n",
       "     User_Count               Developer Rating  \n",
       "0         322.0                Nintendo      E  \n",
       "2         709.0                Nintendo      E  \n",
       "3         192.0                Nintendo      E  \n",
       "6         431.0                Nintendo      E  \n",
       "7         129.0                Nintendo      E  \n",
       "..          ...                     ...    ...  \n",
       "284      3161.0          Valve Software      M  \n",
       "288       785.0  Blizzard Entertainment      T  \n",
       "289       809.0                 EA DICE      M  \n",
       "290       709.0        SCE Santa Monica      M  \n",
       "292       769.0  Obsidian Entertainment      M  \n",
       "\n",
       "[200 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preprocessing code here\n",
    "#get rid of na's\n",
    "game_data.dropna(inplace=True)\n",
    "print(game_data.shape)\n",
    "game_data.head()\n",
    "game_data[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>PS</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>GT Interactive</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.33</td>\n",
       "      <td>6.27</td>\n",
       "      <td>87.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Reflections Interactive</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>X360</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.21</td>\n",
       "      <td>91.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>Epic Games</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>X360</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.51</td>\n",
       "      <td>6.19</td>\n",
       "      <td>73.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Rare Ltd.</td>\n",
       "      <td>E10+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>X360</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.60</td>\n",
       "      <td>6.09</td>\n",
       "      <td>94.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>Epic Games</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>PS4</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Electronic Arts</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.08</td>\n",
       "      <td>82.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>988.0</td>\n",
       "      <td>EA Sports</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Platform  Year_of_Release     Genre               Publisher  NA_Sales  \\\n",
       "0        Wii           2006.0    Sports                Nintendo     41.36   \n",
       "2        Wii           2008.0    Racing                Nintendo     15.68   \n",
       "3        Wii           2009.0    Sports                Nintendo     15.61   \n",
       "6         DS           2006.0  Platform                Nintendo     11.28   \n",
       "7        Wii           2006.0      Misc                Nintendo     13.96   \n",
       "..       ...              ...       ...                     ...       ...   \n",
       "139       PS           1999.0    Action          GT Interactive      3.11   \n",
       "140     X360           2011.0   Shooter  Microsoft Game Studios      4.05   \n",
       "141     X360           2010.0    Sports  Microsoft Game Studios      3.92   \n",
       "142     X360           2006.0   Shooter  Microsoft Game Studios      3.54   \n",
       "143      PS4           2014.0    Sports         Electronic Arts      0.80   \n",
       "\n",
       "     EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0       28.96      3.77         8.45         82.53          76.0   \n",
       "2       12.76      3.79         3.29         35.52          82.0   \n",
       "3       10.93      3.28         2.95         32.77          80.0   \n",
       "6        9.14      6.50         2.88         29.80          89.0   \n",
       "7        9.18      2.93         2.84         28.92          58.0   \n",
       "..        ...       ...          ...           ...           ...   \n",
       "139      2.80      0.02         0.33          6.27          87.0   \n",
       "140      1.59      0.07         0.50          6.21          91.0   \n",
       "141      1.73      0.03         0.51          6.19          73.0   \n",
       "142      1.88      0.07         0.60          6.09          94.0   \n",
       "143      4.33      0.05         0.90          6.08          82.0   \n",
       "\n",
       "     Critic_Count User_Score  User_Count                Developer Rating  \n",
       "0            51.0          8       322.0                 Nintendo      E  \n",
       "2            73.0        8.3       709.0                 Nintendo      E  \n",
       "3            73.0          8       192.0                 Nintendo      E  \n",
       "6            65.0        8.5       431.0                 Nintendo      E  \n",
       "7            41.0        6.6       129.0                 Nintendo      E  \n",
       "..            ...        ...         ...                      ...    ...  \n",
       "139          22.0        8.1        78.0  Reflections Interactive      T  \n",
       "140          96.0        7.8      1504.0               Epic Games      M  \n",
       "141          51.0        7.4        95.0                Rare Ltd.   E10+  \n",
       "142          88.0        8.3      2295.0               Epic Games      M  \n",
       "143          47.0        5.7       988.0                EA Sports      E  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get rid of name's  they are unnecessary\n",
    "game_data = game_data.drop(\"Name\", axis=1)\n",
    "print(game_data.shape)\n",
    "game_data.head()\n",
    "game_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Platform            object\n",
       "Year_of_Release    float64\n",
       "Genre               object\n",
       "Publisher           object\n",
       "NA_Sales           float64\n",
       "EU_Sales           float64\n",
       "JP_Sales           float64\n",
       "Other_Sales        float64\n",
       "Global_Sales       float64\n",
       "Critic_Score       float64\n",
       "Critic_Count       float64\n",
       "User_Score          object\n",
       "User_Count         float64\n",
       "Developer           object\n",
       "Rating              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature data types.\n",
    "game_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train/test sets code here (if applicable)\n",
    "\n",
    "X = set(game_data.columns) \n",
    "X = game_data.drop(\"Rating\", axis=1) \n",
    "y = game_data['Rating'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 14)\n",
      "(6825,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Platform  Year_of_Release     Genre Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
       "0      Wii           2006.0    Sports  Nintendo     41.36     28.96      3.77   \n",
       "2      Wii           2008.0    Racing  Nintendo     15.68     12.76      3.79   \n",
       "3      Wii           2009.0    Sports  Nintendo     15.61     10.93      3.28   \n",
       "6       DS           2006.0  Platform  Nintendo     11.28      9.14      6.50   \n",
       "7      Wii           2006.0      Misc  Nintendo     13.96      9.18      2.93   \n",
       "\n",
       "   Other_Sales  Global_Sales  Critic_Score  Critic_Count User_Score  \\\n",
       "0         8.45         82.53          76.0          51.0          8   \n",
       "2         3.29         35.52          82.0          73.0        8.3   \n",
       "3         2.95         32.77          80.0          73.0          8   \n",
       "6         2.88         29.80          89.0          65.0        8.5   \n",
       "7         2.84         28.92          58.0          41.0        6.6   \n",
       "\n",
       "   User_Count Developer  \n",
       "0       322.0  Nintendo  \n",
       "2       709.0  Nintendo  \n",
       "3       192.0  Nintendo  \n",
       "6       431.0  Nintendo  \n",
       "7       129.0  Nintendo  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    E\n",
       "2    E\n",
       "3    E\n",
       "6    E\n",
       "7    E\n",
       "Name: Rating, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 1678)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>3DS</th>\n",
       "      <th>...</th>\n",
       "      <th>h.a.n.d. Inc.</th>\n",
       "      <th>iNiS</th>\n",
       "      <th>id Software</th>\n",
       "      <th>id Software, Nerve Software</th>\n",
       "      <th>id Software, Raven Software</th>\n",
       "      <th>n-Space</th>\n",
       "      <th>neo Software</th>\n",
       "      <th>odenis studio</th>\n",
       "      <th>syn Sophia</th>\n",
       "      <th>zSlide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1997.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.12</td>\n",
       "      <td>96.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3161.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.09</td>\n",
       "      <td>91.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4.08</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>809.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.07</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>4.05</td>\n",
       "      <td>84.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>769.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1678 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year_of_Release  NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \\\n",
       "0             2006.0     41.36     28.96      3.77         8.45         82.53   \n",
       "2             2008.0     15.68     12.76      3.79         3.29         35.52   \n",
       "3             2009.0     15.61     10.93      3.28         2.95         32.77   \n",
       "6             2006.0     11.28      9.14      6.50         2.88         29.80   \n",
       "7             2006.0     13.96      9.18      2.93         2.84         28.92   \n",
       "..               ...       ...       ...       ...          ...           ...   \n",
       "284           1997.0      4.03      0.00      0.09         0.00          4.12   \n",
       "288           2007.0      2.57      1.52      0.00         0.00          4.09   \n",
       "289           2016.0      1.10      2.15      0.21         0.61          4.08   \n",
       "290           2007.0      2.32      0.04      0.04         1.67          4.07   \n",
       "292           2010.0      2.66      1.03      0.04         0.33          4.05   \n",
       "\n",
       "     Critic_Score  Critic_Count  User_Count  3DS  ...  h.a.n.d. Inc.  iNiS  \\\n",
       "0            76.0          51.0       322.0    0  ...              0     0   \n",
       "2            82.0          73.0       709.0    0  ...              0     0   \n",
       "3            80.0          73.0       192.0    0  ...              0     0   \n",
       "6            89.0          65.0       431.0    0  ...              0     0   \n",
       "7            58.0          41.0       129.0    0  ...              0     0   \n",
       "..            ...           ...         ...  ...  ...            ...   ...   \n",
       "284          96.0          24.0      3161.0    0  ...              0     0   \n",
       "288          91.0          46.0       785.0    0  ...              0     0   \n",
       "289          88.0          31.0       809.0    0  ...              0     0   \n",
       "290          93.0          70.0       709.0    0  ...              0     0   \n",
       "292          84.0          81.0       769.0    0  ...              0     0   \n",
       "\n",
       "     id Software  id Software, Nerve Software  id Software, Raven Software  \\\n",
       "0              0                            0                            0   \n",
       "2              0                            0                            0   \n",
       "3              0                            0                            0   \n",
       "6              0                            0                            0   \n",
       "7              0                            0                            0   \n",
       "..           ...                          ...                          ...   \n",
       "284            0                            0                            0   \n",
       "288            0                            0                            0   \n",
       "289            0                            0                            0   \n",
       "290            0                            0                            0   \n",
       "292            0                            0                            0   \n",
       "\n",
       "     n-Space  neo Software  odenis studio  syn Sophia  zSlide  \n",
       "0          0             0              0           0       0  \n",
       "2          0             0              0           0       0  \n",
       "3          0             0              0           0       0  \n",
       "6          0             0              0           0       0  \n",
       "7          0             0              0           0       0  \n",
       "..       ...           ...            ...         ...     ...  \n",
       "284        0             0              0           0       0  \n",
       "288        0             0              0           0       0  \n",
       "289        0             0              0           0       0  \n",
       "290        0             0              0           0       0  \n",
       "292        0             0              0           0       0  \n",
       "\n",
       "[200 rows x 1678 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X, prefix='', prefix_sep='')\n",
    "\n",
    "print(X.shape)\n",
    "X.head()\n",
    "X[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year_of_Release    float64\n",
       "NA_Sales           float64\n",
       "EU_Sales           float64\n",
       "JP_Sales           float64\n",
       "Other_Sales        float64\n",
       "                    ...   \n",
       "n-Space              uint8\n",
       "neo Software         uint8\n",
       "odenis studio        uint8\n",
       "syn Sophia           uint8\n",
       "zSlide               uint8\n",
       "Length: 1678, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature data types.\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E', 'M', 'T', 'E10+', 'AO', 'K-A', 'RP'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature data types.\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "2    0\n",
       "3    0\n",
       "6    0\n",
       "7    0\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert from categorical values to numerical\n",
    "y = y.map(lambda x: {'E' :0, 'E10+' :1, 'T' :2, 'M' :3, 'AO' :4, 'K-A' :5, 'RP' :6}.get(x))\n",
    "y.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, 1, 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature data types.\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 1678)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>3DS</th>\n",
       "      <th>...</th>\n",
       "      <th>h.a.n.d. Inc.</th>\n",
       "      <th>iNiS</th>\n",
       "      <th>id Software</th>\n",
       "      <th>id Software, Nerve Software</th>\n",
       "      <th>id Software, Raven Software</th>\n",
       "      <th>n-Space</th>\n",
       "      <th>neo Software</th>\n",
       "      <th>odenis studio</th>\n",
       "      <th>syn Sophia</th>\n",
       "      <th>zSlide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.341176</td>\n",
       "      <td>42.346639</td>\n",
       "      <td>41.790569</td>\n",
       "      <td>12.886767</td>\n",
       "      <td>31.004904</td>\n",
       "      <td>41.637276</td>\n",
       "      <td>0.413014</td>\n",
       "      <td>1.147975</td>\n",
       "      <td>0.250716</td>\n",
       "      <td>-0.15243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029661</td>\n",
       "      <td>-0.024214</td>\n",
       "      <td>-0.034254</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>-0.043682</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.01712</td>\n",
       "      <td>-0.012105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133743</td>\n",
       "      <td>15.800856</td>\n",
       "      <td>18.221103</td>\n",
       "      <td>12.956315</td>\n",
       "      <td>11.884655</td>\n",
       "      <td>17.694638</td>\n",
       "      <td>0.845647</td>\n",
       "      <td>2.292368</td>\n",
       "      <td>0.909519</td>\n",
       "      <td>-0.15243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029661</td>\n",
       "      <td>-0.024214</td>\n",
       "      <td>-0.034254</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>-0.043682</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.01712</td>\n",
       "      <td>-0.012105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.371202</td>\n",
       "      <td>15.728496</td>\n",
       "      <td>15.558627</td>\n",
       "      <td>11.182831</td>\n",
       "      <td>10.624793</td>\n",
       "      <td>16.294037</td>\n",
       "      <td>0.701436</td>\n",
       "      <td>2.292368</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>-0.15243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029661</td>\n",
       "      <td>-0.024214</td>\n",
       "      <td>-0.034254</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>-0.043682</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.01712</td>\n",
       "      <td>-0.012105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.341176</td>\n",
       "      <td>11.252514</td>\n",
       "      <td>12.954346</td>\n",
       "      <td>22.380122</td>\n",
       "      <td>10.365410</td>\n",
       "      <td>14.781388</td>\n",
       "      <td>1.350385</td>\n",
       "      <td>1.876225</td>\n",
       "      <td>0.436270</td>\n",
       "      <td>-0.15243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029661</td>\n",
       "      <td>-0.024214</td>\n",
       "      <td>-0.034254</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>-0.043682</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.01712</td>\n",
       "      <td>-0.012105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.341176</td>\n",
       "      <td>14.022868</td>\n",
       "      <td>13.012543</td>\n",
       "      <td>9.965734</td>\n",
       "      <td>10.217191</td>\n",
       "      <td>14.333196</td>\n",
       "      <td>-0.884885</td>\n",
       "      <td>0.627797</td>\n",
       "      <td>-0.077835</td>\n",
       "      <td>-0.15243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029661</td>\n",
       "      <td>-0.024214</td>\n",
       "      <td>-0.034254</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>-0.043682</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.01712</td>\n",
       "      <td>-0.012105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1678 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Release   NA_Sales   EU_Sales   JP_Sales  Other_Sales  \\\n",
       "0        -0.341176  42.346639  41.790569  12.886767    31.004904   \n",
       "2         0.133743  15.800856  18.221103  12.956315    11.884655   \n",
       "3         0.371202  15.728496  15.558627  11.182831    10.624793   \n",
       "6        -0.341176  11.252514  12.954346  22.380122    10.365410   \n",
       "7        -0.341176  14.022868  13.012543   9.965734    10.217191   \n",
       "\n",
       "   Global_Sales  Critic_Score  Critic_Count  User_Count      3DS  ...  \\\n",
       "0     41.637276      0.413014      1.147975    0.250716 -0.15243  ...   \n",
       "2     17.694638      0.845647      2.292368    0.909519 -0.15243  ...   \n",
       "3     16.294037      0.701436      2.292368    0.029412 -0.15243  ...   \n",
       "6     14.781388      1.350385      1.876225    0.436270 -0.15243  ...   \n",
       "7     14.333196     -0.884885      0.627797   -0.077835 -0.15243  ...   \n",
       "\n",
       "   h.a.n.d. Inc.      iNiS  id Software  id Software, Nerve Software  \\\n",
       "0      -0.029661 -0.024214    -0.034254                    -0.012105   \n",
       "2      -0.029661 -0.024214    -0.034254                    -0.012105   \n",
       "3      -0.029661 -0.024214    -0.034254                    -0.012105   \n",
       "6      -0.029661 -0.024214    -0.034254                    -0.012105   \n",
       "7      -0.029661 -0.024214    -0.034254                    -0.012105   \n",
       "\n",
       "   id Software, Raven Software   n-Space  neo Software  odenis studio  \\\n",
       "0                    -0.020969 -0.043682     -0.012105      -0.012105   \n",
       "2                    -0.020969 -0.043682     -0.012105      -0.012105   \n",
       "3                    -0.020969 -0.043682     -0.012105      -0.012105   \n",
       "6                    -0.020969 -0.043682     -0.012105      -0.012105   \n",
       "7                    -0.020969 -0.043682     -0.012105      -0.012105   \n",
       "\n",
       "   syn Sophia    zSlide  \n",
       "0    -0.01712 -0.012105  \n",
       "2    -0.01712 -0.012105  \n",
       "3    -0.01712 -0.012105  \n",
       "6    -0.01712 -0.012105  \n",
       "7    -0.01712 -0.012105  \n",
       "\n",
       "[5 rows x 1678 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize X \n",
    "X = (X - X.mean())/X.std()\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5460, 1678)\n",
      "(5460,)\n",
      "(1365, 1678)\n",
      "(1365,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data to train and test with test_size=0.20\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "List your sklearn and tensorflow methods HERE:\n",
    "\n",
    "1- Sklearn Method No.1: Random Forest\n",
    "\n",
    "2- Sklearn Method No.2: MLPClassifier\n",
    "\n",
    "3- Tensorflow Method: Neural Network\n",
    "\n",
    "Individual students need to work with 2 sklearn methods and 1 tensorflow method.\n",
    "\n",
    "Groups should take 2 approaches (both classification and regression) on 1 or 2 datasets, and for each approach (classification/regression) should use 3 methods as described above (6 methods totally).\n",
    "\n",
    "<b>Notice:</b> You should fine-tune at least one hyperparameter of each method by using multiple values (at least 3 different values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding - Groups should add more cell as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import any necessary method/algorithm modules from sklearn and tf/keras here\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn Method 1 code here random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv Score - Random Forest:  0.5009215297583584\n"
     ]
    }
   ],
   "source": [
    "# Create a RandomForestClassifier with n_estimators=100, max_leaf_nodes=16, n_jobs=-1\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=16, n_jobs=-1) \n",
    "# Perform a 10-fold cross validation with scoring 'roc_auc'\n",
    "# Hint: cross validation should be done on the whole dataset\n",
    "\n",
    "rf_cv_score = cross_val_score(rf_clf, X, y)\n",
    "\n",
    "### END CODING HERE ###\n",
    "\n",
    "print(\"Mean cv Score - Random Forest: \", rf_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform 0.03390739910194947\n",
      "Year_of_Release 0.01361243039224714\n",
      "Genre 0.017088690359052628\n",
      "Publisher 0.01234546469482797\n",
      "NA_Sales 0.005342462961380385\n",
      "EU_Sales 0.009649959113460975\n",
      "JP_Sales 0.014944774551477486\n",
      "Other_Sales 0.047343928019926616\n",
      "Global_Sales 0.0843457445771441\n",
      "Critic_Score 0.0\n",
      "Critic_Count 0.0001886507697079949\n",
      "User_Score 0.01565531388332993\n",
      "User_Count 0.01535729230122567\n",
      "Developer 0.0020306218050619566\n",
      "Rating 0.008432087828628067\n"
     ]
    }
   ],
   "source": [
    "# Fit the rf_clf on the training set\n",
    "rf_clf.fit(X_train,y_train)\n",
    "\n",
    "# Get feature_importances of rf for all features\n",
    "for name, score in zip(game_data, rf_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.76       413\n",
      "           1       1.00      0.06      0.11       175\n",
      "           2       0.50      0.83      0.62       488\n",
      "           3       0.83      0.31      0.45       288\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.60      1365\n",
      "   macro avg       0.61      0.39      0.39      1365\n",
      "weighted avg       0.70      0.60      0.56      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn Method 2 code here MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv Score - MLPClassifier:  0.636003969923233\n"
     ]
    }
   ],
   "source": [
    "# Create a MLPClassifier with activation = 'relu', solver='sgd', hidden_layer_sizes=(100,150),random_state=1) \n",
    "mlp_clf = MLPClassifier(activation = 'relu', solver='sgd', hidden_layer_sizes=(100,150),random_state=1) \n",
    "\n",
    "mlp_cv_score = cross_val_score(mlp_clf, X, y)\n",
    "\n",
    "### END CODING HERE ###\n",
    "\n",
    "print(\"Mean cv Score - MLPClassifier: \", mlp_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-160.66806363  -20.76529757   76.41746736 ...  -73.40199516\n",
      "    13.028072    -73.40199516]\n",
      " [ 106.20564952   23.5699802   -56.28290236 ...   97.11480989\n",
      "   -37.91151834  -68.11230653]\n",
      " [ -93.55409598  -42.66456833   -1.43483503 ...  -76.68232839\n",
      "   -50.03224761   88.54478803]\n",
      " ...\n",
      " [   8.56600092    1.66321217   -6.29366009 ...  -66.06663747\n",
      "   -35.01829341  -66.06663747]\n",
      " [   4.01610664    0.34430637  -18.10066287 ...  -66.51450584\n",
      "   -35.65172135   16.09905237]\n",
      " [   6.909283     -2.3822002    -3.49276388 ...  -66.45398309\n",
      "   -35.56612298   16.15957512]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the mlp_clf on the training set\n",
    "\n",
    "mlp_clf = Perceptron(tol=1e-3, random_state=0)\n",
    "mlp_clf.fit(X, y)\n",
    "\n",
    "coeffs = mlp_clf.coef_\n",
    "\n",
    "print(coeffs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       413\n",
      "           1       0.63      0.62      0.63       175\n",
      "           2       0.80      0.76      0.78       488\n",
      "           3       0.84      0.79      0.82       288\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.20      1.00      0.33         1\n",
      "\n",
      "    accuracy                           0.79      1365\n",
      "   macro avg       0.47      0.58      0.49      1365\n",
      "weighted avg       0.80      0.79      0.79      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow/keras Method code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data to tf\n",
    "train_tensor = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\n",
    "test_tensor = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [ 0.37120196 -0.07699467 -0.32893862 ... -0.01210455 -0.01711967\n",
      " -0.01210455], Target: 1\n",
      "Features: [ 0.13374265 -0.22171467 -0.02340852 ... -0.01210455 -0.01711967\n",
      " -0.01210455], Target: 0\n",
      "Features: [-1.5284725  -0.3974461  -0.34348768 ... -0.01210455 -0.01711967\n",
      " -0.01210455], Target: 0\n",
      "Features: [ 1.7959578   2.20751385  4.41405253 ... -0.01210455 -0.01711967\n",
      " -0.01210455], Target: 3\n",
      "Features: [-1.29101319 -0.29407467 -0.2125462  ... -0.01210455 -0.01711967\n",
      " -0.01210455], Target: 2\n"
     ]
    }
   ],
   "source": [
    "for feat, targ in train_tensor.take(5):\n",
    "  print ('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
     ]
    }
   ],
   "source": [
    "# Batch train and test data\n",
    "train_batch = train_tensor.shuffle(len(X_train)).batch(10)\n",
    "test_batch = test_tensor.shuffle(len(X_test)).batch(10)\n",
    "\n",
    "print(type(train_batch))\n",
    "print(type(test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "# Build a Sequential neural network - a classifier model\n",
    "def build_model():\n",
    "    nn_clf = tf.keras.Sequential([\n",
    "        # Create a dense layer with 1000 units, input_dim=1678, and 'relu' activation function ~ 1 line\n",
    "        tf.keras.layers.Dense(1000, input_dim=1678, activation='relu'), \n",
    "        # Create a dense layer with 500 units, and 'relu' activation function \n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(200, activation='relu'), \n",
    "        tf.keras.layers.Dense(70, activation='relu'), \n",
    "        tf.keras.layers.Dense(20, activation='relu'), \n",
    "      \n",
    "        #output layer\n",
    "        tf.keras.layers.Dense(7, activation='softmax')\n",
    "        ])  \n",
    "    return nn_clf\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "# Compile the model \n",
    "model = build_model()\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy']) \n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "546/546 [==============================] - 19s 35ms/step - loss: 1.0465 - sparse_categorical_accuracy: 0.5793\n",
      "Epoch 2/20\n",
      "546/546 [==============================] - 13s 23ms/step - loss: 0.7083 - sparse_categorical_accuracy: 0.7401 1s - loss: 0.7056 - sparse_categori\n",
      "Epoch 3/20\n",
      "546/546 [==============================] - 15s 27ms/step - loss: 0.6160 - sparse_categorical_accuracy: 0.7885\n",
      "Epoch 4/20\n",
      "546/546 [==============================] - 13s 23ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.8143TA: 2s - loss: 0.\n",
      "Epoch 5/20\n",
      "546/546 [==============================] - 12s 22ms/step - loss: 0.4730 - sparse_categorical_accuracy: 0.8344 1s - loss: 0.4726 - sparse_categor\n",
      "Epoch 6/20\n",
      "546/546 [==============================] - 15s 27ms/step - loss: 0.4323 - sparse_categorical_accuracy: 0.8540\n",
      "Epoch 7/20\n",
      "546/546 [==============================] - 14s 25ms/step - loss: 0.3830 - sparse_categorical_accuracy: 0.8751\n",
      "Epoch 8/20\n",
      "546/546 [==============================] - 12s 22ms/step - loss: 0.3583 - sparse_categorical_accuracy: 0.8868-  - ETA: 2s - loss: 0.3505 - sparse_categorical_accura - ETA: 2s - loss: 0.3511 - spa\n",
      "Epoch 9/20\n",
      "546/546 [==============================] - 12s 22ms/step - loss: 0.3379 - sparse_categorical_accuracy: 0.8985\n",
      "Epoch 10/20\n",
      "546/546 [==============================] - 12s 21ms/step - loss: 0.3283 - sparse_categorical_accuracy: 0.9007\n",
      "Epoch 11/20\n",
      "546/546 [==============================] - 11s 21ms/step - loss: 0.3066 - sparse_categorical_accuracy: 0.9077\n",
      "Epoch 12/20\n",
      "546/546 [==============================] - 11s 21ms/step - loss: 0.2715 - sparse_categorical_accuracy: 0.9216\n",
      "Epoch 13/20\n",
      "546/546 [==============================] - 11s 20ms/step - loss: 0.3123 - sparse_categorical_accuracy: 0.9269\n",
      "Epoch 14/20\n",
      "546/546 [==============================] - 15s 28ms/step - loss: 0.2664 - sparse_categorical_accuracy: 0.9299\n",
      "Epoch 15/20\n",
      "546/546 [==============================] - 15s 28ms/step - loss: 0.2363 - sparse_categorical_accuracy: 0.9370 3s - lo\n",
      "Epoch 16/20\n",
      "546/546 [==============================] - 12s 22ms/step - loss: 0.2544 - sparse_categorical_accuracy: 0.9361 1s - loss: 0.2587 - sparse\n",
      "Epoch 17/20\n",
      "546/546 [==============================] - 12s 22ms/step - loss: 0.2636 - sparse_categorical_accuracy: 0.9390 0s - loss: 0.2649 - sparse_categorical_accuracy: 0.93\n",
      "Epoch 18/20\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.2530 - sparse_categorical_accuracy: 0.9443 4s - loss: 0.2687 - s - E\n",
      "Epoch 19/20\n",
      "546/546 [==============================] - 12s 22ms/step - loss: 0.2514 - sparse_categorical_accuracy: 0.9484 3s\n",
      "Epoch 20/20\n",
      "546/546 [==============================] - 12s 22ms/step - loss: 0.1964 - sparse_categorical_accuracy: 0.9531\n"
     ]
    }
   ],
   "source": [
    " nn_clf_historystory = model.fit(train_batch, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, ..., 2, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       413\n",
      "           1       0.47      0.59      0.52       175\n",
      "           2       0.65      0.73      0.69       488\n",
      "           3       0.84      0.62      0.71       288\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.69      1365\n",
      "   macro avg       0.55      0.53      0.54      1365\n",
      "weighted avg       0.71      0.69      0.69      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(nn_clf_historystory.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "\n",
    "# set the y-axis range to [0-1]\n",
    "plt.gca().set_ylim(0, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate nn_clf model on test_batch using .evaluate method\n",
    "model.evaluate(test_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1000)              1679000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                14070     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                1420      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 147       \n",
      "=================================================================\n",
      "Total params: 2,295,337\n",
      "Trainable params: 2,295,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "# Get class probabilities for nn - ignore the warning\n",
    "nn_preds = model.predict(X_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.999993e-01, 8.125896e-26, 7.043426e-07, 1.354381e-37,\n",
       "       0.000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See class probabilities predicted by nn classifier\n",
    "nn_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEARNING RATE FOR LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "171/171 [==============================] - 9s 53ms/step - loss: 1.1213 - sparse_categorical_accuracy: 0.5577\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 4s 26ms/step - loss: 0.6165 - sparse_categorical_accuracy: 0.7749\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 4s 26ms/step - loss: 0.4790 - sparse_categorical_accuracy: 0.8220:\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 4s 26ms/step - loss: 0.3880 - sparse_categorical_accuracy: 0.8496\n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.3181 - sparse_categorical_accuracy: 0.8716: 1s - loss: 0.3088 - sparse_categorical\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.2632 - sparse_categorical_accuracy: 0.8982\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.2253 - sparse_categorical_accuracy: 0.9152\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 6s 34ms/step - loss: 0.1647 - sparse_categorical_accuracy: 0.9370: 2s -\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 5s 31ms/step - loss: 0.1452 - sparse_categorical_accuracy: 0.9487\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.1154 - sparse_categorical_accuracy: 0.9568\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9641\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 6s 33ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9689\n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.0897 - sparse_categorical_accuracy: 0.9740\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.0779 - sparse_categorical_accuracy: 0.9800\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9828\n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.0809 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 6s 35ms/step - loss: 0.0656 - sparse_categorical_accuracy: 0.9844\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 5s 31ms/step - loss: 0.0663 - sparse_categorical_accuracy: 0.9859: 2s - loss: 0.0637 - sparse_cate\n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 0.0683 - sparse_categorical_accuracy: 0.9846\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 0.0438 - sparse_categorical_accuracy: 0.9890\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 4.0856 - sparse_categorical_accuracy: 0.6886\n",
      "lr 0.001\n",
      "Epoch 1/20\n",
      "171/171 [==============================] - 9s 50ms/step - loss: 1.1466 - sparse_categorical_accuracy: 0.5504\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 4s 26ms/step - loss: 0.6776 - sparse_categorical_accuracy: 0.7537\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 4s 26ms/step - loss: 0.5188 - sparse_categorical_accuracy: 0.8088: 2\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.4545 - sparse_categorical_accuracy: 0.8377\n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3842 - sparse_categorical_accuracy: 0.8659: 2s - loss: 0.361\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3347 - sparse_categorical_accuracy: 0.8885: 1s - loss: 0.3076 - sparse_\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 0.2766 - sparse_categorical_accuracy: 0.9053: 0s - loss: 0.2670 - sparse_categorical_accurac\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.2279 - sparse_categorical_accuracy: 0.9211\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.2040 - sparse_categorical_accuracy: 0.9326: 2s - loss: 0.\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.1832 - sparse_categorical_accuracy: 0.9465: 1s - loss: 0.1580 - spar\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.1560 - sparse_categorical_accuracy: 0.9553\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1381 - sparse_categorical_accuracy: 0.9623\n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1436 - sparse_categorical_accuracy: 0.9656: 1s - loss: 0.1129 - sparse_\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1467 - sparse_categorical_accuracy: 0.9736\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1794 - sparse_categorical_accuracy: 0.9696\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1232 - sparse_categorical_accuracy: 0.9744: 0s - loss: 0.1161 - sparse_categorical_accurac\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1184 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9777\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9788\n",
      "43/43 [==============================] - 1s 19ms/step - loss: 6.9337 - sparse_categorical_accuracy: 0.6894\n",
      "lr 0.002\n",
      "Epoch 1/20\n",
      "171/171 [==============================] - 6s 35ms/step - loss: 1.2314 - sparse_categorical_accuracy: 0.52602422 - sparse_categorical_accuracy: 0 - 6s 35ms/step - loss: 1.2314 - sparse_categorical_accuracy: 0.526\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7738 - sparse_categorical_accuracy: 0.7104\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6446 - sparse_categorical_accuracy: 0.7716\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.5706 - sparse_categorical_accuracy: 0.8048\n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.5009 - sparse_categorical_accuracy: 0.8249\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.5345 - sparse_categorical_accuracy: 0.8451\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3735 - sparse_categorical_accuracy: 0.8661\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.3448 - sparse_categorical_accuracy: 0.8808\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3441 - sparse_categorical_accuracy: 0.8897: 0s - loss: 0.3390 - sparse_categorical_accuracy: 0. - ETA: 0s - loss: 0.3432 - sparse_categorical_accuracy: 0.8\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.2977 - sparse_categorical_accuracy: 0.9095: 2s - loss: 0.2414 - s\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.2401 - sparse_categorical_accuracy: 0.9256\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.2572 - sparse_categorical_accuracy: 0.9278: 3s - \n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1977 - sparse_categorical_accuracy: 0.9408\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.2691 - sparse_categorical_accuracy: 0.9432\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6599 - sparse_categorical_accuracy: 0.9443\n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2560 - sparse_categorical_accuracy: 0.9421\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.2267 - sparse_categorical_accuracy: 0.9337\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.2025 - sparse_categorical_accuracy: 0.9463: \n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.2398 - sparse_categorical_accuracy: 0.9478: 0s - loss: 0.2420 - sparse_categorical_acc\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2876 - sparse_categorical_accuracy: 0.9582: 2s - loss: 0.\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 10.1799 - sparse_categorical_accuracy: 0.6564\n",
      "lr 0.003\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 6s 33ms/step - loss: 1.3591 - sparse_categorical_accuracy: 0.5225\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.8235 - sparse_categorical_accuracy: 0.7081\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7246 - sparse_categorical_accuracy: 0.7617: 1s - loss: 0.6719 - sparse_categorica\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6021 - sparse_categorical_accuracy: 0.7978\n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.5391 - sparse_categorical_accuracy: 0.8152\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.5274 - sparse_categorical_accuracy: 0.8335\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4587 - sparse_categorical_accuracy: 0.8511\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.4416 - sparse_categorical_accuracy: 0.8606\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.4658 - sparse_categorical_accuracy: 0.8793: 2s - loss: 0.3816 - spars\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4850 - sparse_categorical_accuracy: 0.8813\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 4s 26ms/step - loss: 0.4622 - sparse_categorical_accuracy: 0.8839: 2s - loss: 0.321\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4215 - sparse_categorical_accuracy: 0.8916\n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.3700 - sparse_categorical_accuracy: 0.8745\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.5424 - sparse_categorical_accuracy: 0.8879: 0s - loss: 0.5442 - sparse_categorical_accuracy: 0.887\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.5208 - sparse_categorical_accuracy: 0.8821\n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4475 - sparse_categorical_accuracy: 0.8949\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.5347 - sparse_categorical_accuracy: 0.9062: 3s\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.4346 - sparse_categorical_accuracy: 0.8989\n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6806 - sparse_categorical_accuracy: 0.9027\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3160 - sparse_categorical_accuracy: 0.9147\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 4.2535 - sparse_categorical_accuracy: 0.6432\n",
      "lr 0.004\n",
      "Epoch 1/20\n",
      "171/171 [==============================] - 5s 32ms/step - loss: 1.4327 - sparse_categorical_accuracy: 0.4951\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.9486 - sparse_categorical_accuracy: 0.6899: 3s\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.7450 - sparse_categorical_accuracy: 0.7454: 1s - loss: 0.7518 - sparse_categ\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7261 - sparse_categorical_accuracy: 0.7698: 3s - - ETA: 0s - loss: 0.7260 - sparse_categorical_accuracy: 0.77\n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.7288 - sparse_categorical_accuracy: 0.7819\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.5949 - sparse_categorical_accuracy: 0.7916: 2s - loss: 0.5\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.5531 - sparse_categorical_accuracy: 0.8247\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6680 - sparse_categorical_accuracy: 0.8352\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.5236 - sparse_categorical_accuracy: 0.8385\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.7804 - sparse_categorical_accuracy: 0.8582: 0s - loss: 0.8776 - sparse_categorical_a\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.5549 - sparse_categorical_accuracy: 0.8262\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.5406 - sparse_categorical_accuracy: 0.8121\n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.5636 - sparse_categorical_accuracy: 0.8493\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6282 - sparse_categorical_accuracy: 0.7533\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.1367 - sparse_categorical_accuracy: 0.8348\n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7695 - sparse_categorical_accuracy: 0.8123\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 2.5428 - sparse_categorical_accuracy: 0.7936\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.5814 - sparse_categorical_accuracy: 0.8009\n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.9819 - sparse_categorical_accuracy: 0.7940\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 1.2002 - sparse_categorical_accuracy: 0.7912\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 2.7684 - sparse_categorical_accuracy: 0.5897\n",
      "lr 0.005\n",
      "Epoch 1/20\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 1.7214 - sparse_categorical_accuracy: 0.4870\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.9136 - sparse_categorical_accuracy: 0.6725\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.7977 - sparse_categorical_accuracy: 0.7317\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.7698 - sparse_categorical_accuracy: 0.7586\n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6526 - sparse_categorical_accuracy: 0.7791: 1s - loss: 0.6446 - sparse_catego\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7372 - sparse_categorical_accuracy: 0.7941\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.9480 - sparse_categorical_accuracy: 0.8147: 1s - loss: 1.2413 - sparse_cat\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6287 - sparse_categorical_accuracy: 0.8137\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.5687 - sparse_categorical_accuracy: 0.8110\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.7710 - sparse_categorical_accuracy: 0.8117: 0s - loss: 0.7934 - sparse_categorical_acc\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 1.0013 - sparse_categorical_accuracy: 0.7996\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.7459 - sparse_categorical_accuracy: 0.7974: 2s - loss: 0.7210 -\n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.7231 - sparse_categorical_accuracy: 0.7832\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 5s 27ms/step - loss: 0.7000 - sparse_categorical_accuracy: 0.7923\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 1.6033 - sparse_categorical_accuracy: 0.7853: 2s - loss: 0.8654 - \n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.9121 - sparse_categorical_accuracy: 0.8015\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.8875 - sparse_categorical_accuracy: 0.7751\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 1.7686 - sparse_categorical_accuracy: 0.7775:\n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 2.3378 - sparse_categorical_accuracy: 0.7744\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.6261 - sparse_categorical_accuracy: 0.8082\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 4.1025 - sparse_categorical_accuracy: 0.6103\n",
      "lr 0.006\n",
      "Epoch 1/20\n",
      "171/171 [==============================] - 5s 27ms/step - loss: 2.7687 - sparse_categorical_accuracy: 0.4009\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.1833 - sparse_categorical_accuracy: 0.5678\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 1.3154 - sparse_categorical_accuracy: 0.6227\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.0505 - sparse_categorical_accuracy: 0.6462\n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.0831 - sparse_categorical_accuracy: 0.6553\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.5428 - sparse_categorical_accuracy: 0.6705\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.3218 - sparse_categorical_accuracy: 0.6793\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 1.6862 - sparse_categorical_accuracy: 0.6918: 1s - loss: 1.9667 - sparse_cate\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.1064 - sparse_categorical_accuracy: 0.6861\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8849 - sparse_categorical_accuracy: 0.6976\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 1.1110 - sparse_categorical_accuracy: 0.7051: 1s - loss: 1.3933 - spa\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7499 - sparse_categorical_accuracy: 0.7090\n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 1.1752 - sparse_categorical_accuracy: 0.7026\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.8857 - sparse_categorical_accuracy: 0.7130\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.8840 - sparse_categorical_accuracy: 0.7099\n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7678 - sparse_categorical_accuracy: 0.7286: 2s - l\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 2.3397 - sparse_categorical_accuracy: 0.7267\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.7711 - sparse_categorical_accuracy: 0.7317\n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 1.8253 - sparse_categorical_accuracy: 0.6980\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.9777 - sparse_categorical_accuracy: 0.7295\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 3.5769 - sparse_categorical_accuracy: 0.6051\n",
      "lr 0.007\n",
      "Epoch 1/20\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 1.8300 - sparse_categorical_accuracy: 0.4240\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.2329 - sparse_categorical_accuracy: 0.5551\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.1863 - sparse_categorical_accuracy: 0.5890\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.4064 - sparse_categorical_accuracy: 0.6192: 2s - loss: 1.1832 - sparse_categorical_accur - ETA: 2s - loss: 1.0202 - \n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 2.1700 - sparse_categorical_accuracy: 0.6288\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.5598 - sparse_categorical_accuracy: 0.6487\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 1.7834 - sparse_categorical_accuracy: 0.6154\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.5730 - sparse_categorical_accuracy: 0.6348\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.5635 - sparse_categorical_accuracy: 0.6489\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 1.8374 - sparse_categorical_accuracy: 0.6498\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.5142 - sparse_categorical_accuracy: 0.6141\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 1.9699 - sparse_categorical_accuracy: 0.6738: 2s - loss: 0.8523 - sparse_categorical_accuracy: 0.6 - ETA: 1s - loss: 0.8392 - sparse_ca\n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.9532 - sparse_categorical_accuracy: 0.6773\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.8608 - sparse_categorical_accuracy: 0.6385\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 1.0033 - sparse_categorical_accuracy: 0.5848\n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.1855 - sparse_categorical_accuracy: 0.6152\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.3530 - sparse_categorical_accuracy: 0.6712\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.7334 - sparse_categorical_accuracy: 0.6615\n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 1.0441 - sparse_categorical_accuracy: 0.6436\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.2804 - sparse_categorical_accuracy: 0.6791: 2s - loss: 0.\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 2.5519 - sparse_categorical_accuracy: 0.5795\n",
      "lr 0.008\n",
      "Epoch 1/20\n",
      "171/171 [==============================] - 4s 26ms/step - loss: 2.5361 - sparse_categorical_accuracy: 0.4641\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 1.1965 - sparse_categorical_accuracy: 0.5967\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.1541 - sparse_categorical_accuracy: 0.6267: 2s - loss: 1.1\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.9695 - sparse_categorical_accuracy: 0.6537: 4s \n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.9199 - sparse_categorical_accuracy: 0.6755\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 1.1385 - sparse_categorical_accuracy: 0.6687: 2s - loss: 1.6460 -\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.2891 - sparse_categorical_accuracy: 0.6967: 1s - loss: 1.5017 - sparse_categori\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.9647 - sparse_categorical_accuracy: 0.6976\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.2649 - sparse_categorical_accuracy: 0.6985: 1s - loss: 1.8711 - s\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.8214 - sparse_categorical_accuracy: 0.6914\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.8323 - sparse_categorical_accuracy: 0.6899\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.9738 - sparse_categorical_accuracy: 0.7115\n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7620 - sparse_categorical_accuracy: 0.7220: 0s - loss: 0.7586 - sparse_categorical_accuracy: 0\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.8557 - sparse_categorical_accuracy: 0.7299\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.9274 - sparse_categorical_accuracy: 0.7288: 0s - loss: 0.9650 - sparse_categorical_accuracy:\n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.7573 - sparse_categorical_accuracy: 0.7361\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.7041 - sparse_categorical_accuracy: 0.7443\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.9903 - sparse_categorical_accuracy: 0.7410: 2s - loss: 1.3404\n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 1.0069 - sparse_categorical_accuracy: 0.7293\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.8691 - sparse_categorical_accuracy: 0.6672\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 3.4924 - sparse_categorical_accuracy: 0.5319\n",
      "lr 0.009000000000000001\n"
     ]
    }
   ],
   "source": [
    "### START CODING HERE ###\n",
    "results = []\n",
    "histories = []\n",
    "\n",
    "learning_rates = np.arange(0.001, 0.01, 0.001) \n",
    "for lr in learning_rates: #lr is learning rate\n",
    "    train_batch = train_tensor.shuffle(len(X_train)).batch(32)\n",
    "    test_batch = test_tensor.shuffle(len(X_test)).batch(32)\n",
    "    model= build_model()\n",
    "    optimizer = tf.keras.optimizers.RMSprop(lr) \n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "    nn_clf_historystory = model.fit(train_batch, epochs=20)\n",
    "    result= model.evaluate(test_batch)\n",
    "    print(\"lr\",lr)\n",
    "\n",
    "    results.append(result)\n",
    "    histories.append(nn_clf_historystory)\n",
    "    \n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6886447,\n",
       " 0.6893773,\n",
       " 0.6564103,\n",
       " 0.64322346,\n",
       " 0.5897436,\n",
       " 0.61025643,\n",
       " 0.6051282,\n",
       " 0.5794872,\n",
       " 0.53186816]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(results))\n",
    "acc = [x[1] for x in results]\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23ccb16b688>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Impact of Learning Rate on Accuracy')\n",
    "plt.xlabel('learning_rate', fontsize=14)\n",
    "plt.ylabel('accuracy', fontsize=14)\n",
    "plt.plot(learning_rates, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPOCH FOR LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 1.0582 - sparse_categorical_accuracy: 0.5698\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6391 - sparse_categorical_accuracy: 0.7582: 2s - loss: 0.\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4863 - sparse_categorical_accuracy: 0.8181\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3999 - sparse_categorical_accuracy: 0.8502\n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3343 - sparse_categorical_accuracy: 0.8723\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2715 - sparse_categorical_accuracy: 0.8936\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2186 - sparse_categorical_accuracy: 0.9165\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1701 - sparse_categorical_accuracy: 0.9344: 2s - los\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1358 - sparse_categorical_accuracy: 0.9487\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1148 - sparse_categorical_accuracy: 0.9608\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0991 - sparse_categorical_accuracy: 0.9736: 2s - loss\n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0895 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0663 - sparse_categorical_accuracy: 0.9799\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9833\n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0463 - sparse_categorical_accuracy: 0.9868: 1s - loss: 0.0395 - sparse_categor\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9868\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0596 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0415 - sparse_categorical_accuracy: 0.9914\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 5.5400 - sparse_categorical_accuracy: 0.6879\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/21\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 1.1075 - sparse_categorical_accuracy: 0.5211s 29ms/step - loss: 1.1453 - spa\n",
      "Epoch 2/21\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6830 - sparse_categorical_accuracy: 0.7392\n",
      "Epoch 3/21\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.5039 - sparse_categorical_accuracy: 0.8073\n",
      "Epoch 4/21\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4186 - sparse_categorical_accuracy: 0.8443\n",
      "Epoch 5/21\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3437 - sparse_categorical_accuracy: 0.8661\n",
      "Epoch 6/21\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2788 - sparse_categorical_accuracy: 0.8892\n",
      "Epoch 7/21\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2303 - sparse_categorical_accuracy: 0.9088\n",
      "Epoch 8/21\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1997 - sparse_categorical_accuracy: 0.9277\n",
      "Epoch 9/21\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1431 - sparse_categorical_accuracy: 0.9441: 1s - loss: 0.1387 - sparse_categorical_accuracy: - ETA: 1s - loss: 0.1316 - sparse_cat\n",
      "Epoch 10/21\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1446 - sparse_categorical_accuracy: 0.9527\n",
      "Epoch 11/21\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1098 - sparse_categorical_accuracy: 0.9619: 2s - \n",
      "Epoch 12/21\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1032 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 13/21\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9731\n",
      "Epoch 14/21\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0883 - sparse_categorical_accuracy: 0.9767\n",
      "Epoch 15/21\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.1467 - sparse_categorical_accuracy: 0.9797\n",
      "Epoch 16/21\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9813\n",
      "Epoch 17/21\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0716 - sparse_categorical_accuracy: 0.9844\n",
      "Epoch 18/21\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1029 - sparse_categorical_accuracy: 0.9837: 0s - loss: 0.0961 - sparse_categorical_accurac - ETA: 0s - loss: 0.0993 - sparse_categorical_accuracy: 0\n",
      "Epoch 19/21\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 20/21\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0686 - sparse_categorical_accuracy: 0.9850\n",
      "Epoch 21/21\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0872 - sparse_categorical_accuracy: 0.9877\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 4.5848 - sparse_categorical_accuracy: 0.6894\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/22\n",
      "171/171 [==============================] - 4s 26ms/step - loss: 1.0675 - sparse_categorical_accuracy: 0.56191388 - sparse_c - 4s 26ms/step - loss: 1.0903 - sparse_categori\n",
      "Epoch 2/22\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6235 - sparse_categorical_accuracy: 0.7614\n",
      "Epoch 3/22\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.4771 - sparse_categorical_accuracy: 0.8211\n",
      "Epoch 4/22\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3942 - sparse_categorical_accuracy: 0.8458\n",
      "Epoch 5/22\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3310 - sparse_categorical_accuracy: 0.8674\n",
      "Epoch 6/22\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2795 - sparse_categorical_accuracy: 0.8929\n",
      "Epoch 7/22\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2305 - sparse_categorical_accuracy: 0.9112\n",
      "Epoch 8/22\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1807 - sparse_categorical_accuracy: 0.9324\n",
      "Epoch 9/22\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1709 - sparse_categorical_accuracy: 0.9392\n",
      "Epoch 10/22\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1156 - sparse_categorical_accuracy: 0.9571\n",
      "Epoch 11/22\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1087 - sparse_categorical_accuracy: 0.9648: 1s - loss: 0.1046 - sparse_categoric\n",
      "Epoch 12/22\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 13/22\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0808 - sparse_categorical_accuracy: 0.9738: 1s - loss: 0.0591 - spar\n",
      "Epoch 14/22\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0595 - sparse_categorical_accuracy: 0.9815\n",
      "Epoch 15/22\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9826\n",
      "Epoch 16/22\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9830\n",
      "Epoch 17/22\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9874\n",
      "Epoch 18/22\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0509 - sparse_categorical_accuracy: 0.9872: 1s - loss: 0.0427 - sparse\n",
      "Epoch 19/22\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0613 - sparse_categorical_accuracy: 0.9890: 3s - loss: 0.0258 - sparse_categorical_acc - ETA: 2s - loss: 0.0394 - sparse_ - ETA: 0s - loss: 0.0559 - sparse_categorical_accuracy\n",
      "Epoch 20/22\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0354 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 21/22\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0334 - sparse_categorical_accuracy: 0.9916A: \n",
      "Epoch 22/22\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0479 - sparse_categorical_accuracy: 0.9888TA: 3s - loss: 0.0295 - sparse_categorical_accuracy:  - ETA: 2s - l\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 3.6315 - sparse_categorical_accuracy: 0.6755\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/23\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 1.1599 - sparse_categorical_accuracy: 0.5454loss: 1.238\n",
      "Epoch 2/23\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6554 - sparse_categorical_accuracy: 0.7511\n",
      "Epoch 3/23\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.4892 - sparse_categorical_accuracy: 0.8148\n",
      "Epoch 4/23\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.3990 - sparse_categorical_accuracy: 0.8449\n",
      "Epoch 5/23\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.3419 - sparse_categorical_accuracy: 0.8661\n",
      "Epoch 6/23\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2865 - sparse_categorical_accuracy: 0.8868A: 3s -\n",
      "Epoch 7/23\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2310 - sparse_categorical_accuracy: 0.9071\n",
      "Epoch 8/23\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1892 - sparse_categorical_accuracy: 0.9311\n",
      "Epoch 9/23\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1535 - sparse_categorical_accuracy: 0.9458\n",
      "Epoch 10/23\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1258 - sparse_categorical_accuracy: 0.9588\n",
      "Epoch 11/23\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0989 - sparse_categorical_accuracy: 0.9663: 3s - \n",
      "Epoch 12/23\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9723: 1s - loss: 0.0798 - s\n",
      "Epoch 13/23\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0787 - sparse_categorical_accuracy: 0.9742: 3s \n",
      "Epoch 14/23\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0588 - sparse_categorical_accuracy: 0.9835\n",
      "Epoch 15/23\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9835\n",
      "Epoch 16/23\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0655 - sparse_categorical_accuracy: 0.9839\n",
      "Epoch 17/23\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0531 - sparse_categorical_accuracy: 0.9855\n",
      "Epoch 18/23\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0529 - sparse_categorical_accuracy: 0.9870: 0s - loss: 0.0583 - sparse_categorical_accuracy: 0 - ETA: 0s - loss: 0.0570 - sparse_categorical_accuracy\n",
      "Epoch 19/23\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0644 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 20/23\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9886\n",
      "Epoch 21/23\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0680 - sparse_categorical_accuracy: 0.9883: 1s - loss: 0.0299 - sparse\n",
      "Epoch 22/23\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0531 - sparse_categorical_accuracy: 0.9885\n",
      "Epoch 23/23\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0435 - sparse_categorical_accuracy: 0.9897\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 3.3268 - sparse_categorical_accuracy: 0.6952\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/24\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 1.0647 - sparse_categorical_accuracy: 0.55771047 - sparse_ca\n",
      "Epoch 2/24\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6329 - sparse_categorical_accuracy: 0.7599\n",
      "Epoch 3/24\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.4875 - sparse_categorical_accuracy: 0.8179\n",
      "Epoch 4/24\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.4038 - sparse_categorical_accuracy: 0.8505\n",
      "Epoch 5/24\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3287 - sparse_categorical_accuracy: 0.8777\n",
      "Epoch 6/24\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2743 - sparse_categorical_accuracy: 0.8951\n",
      "Epoch 7/24\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2352 - sparse_categorical_accuracy: 0.9181\n",
      "Epoch 8/24\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1873 - sparse_categorical_accuracy: 0.9288\n",
      "Epoch 9/24\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1440 - sparse_categorical_accuracy: 0.9473\n",
      "Epoch 10/24\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1124 - sparse_categorical_accuracy: 0.9592\n",
      "Epoch 11/24\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1164 - sparse_categorical_accuracy: 0.9647\n",
      "Epoch 12/24\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9740\n",
      "Epoch 13/24\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9764: 0s - loss: 0.0874 - sparse_categorical_\n",
      "Epoch 14/24\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9802\n",
      "Epoch 15/24\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0771 - sparse_categorical_accuracy: 0.9821\n",
      "Epoch 16/24\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9852\n",
      "Epoch 17/24\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9863: 2s - loss: 0.\n",
      "Epoch 18/24\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9839\n",
      "Epoch 19/24\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0542 - sparse_categorical_accuracy: 0.9903\n",
      "Epoch 20/24\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9863\n",
      "Epoch 21/24\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 22/24\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0536 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 23/24\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0499 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 24/24\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9907\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 4.9813 - sparse_categorical_accuracy: 0.6762\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/25\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 1.1458 - sparse_categorical_accuracy: 0.5342\n",
      "Epoch 2/25\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6294 - sparse_categorical_accuracy: 0.7658\n",
      "Epoch 3/25\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4730 - sparse_categorical_accuracy: 0.8216\n",
      "Epoch 4/25\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3973 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 5/25\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3274 - sparse_categorical_accuracy: 0.8676\n",
      "Epoch 6/25\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2743 - sparse_categorical_accuracy: 0.8938\n",
      "Epoch 7/25\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2187 - sparse_categorical_accuracy: 0.9161\n",
      "Epoch 8/25\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1860 - sparse_categorical_accuracy: 0.9300\n",
      "Epoch 9/25\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1513 - sparse_categorical_accuracy: 0.9454\n",
      "Epoch 10/25\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1277 - sparse_categorical_accuracy: 0.9579\n",
      "Epoch 11/25\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9661: 2s \n",
      "Epoch 12/25\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1430 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0959 - sparse_categorical_accuracy: 0.9762: 3s - loss: 0.04\n",
      "Epoch 14/25\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.0676 - sparse_categorical_accuracy: 0.9780: 3s - loss: 0.0526 - sparse_categorica - ETA: 2s - loss: 0.0643 \n",
      "Epoch 15/25\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0640 - sparse_categorical_accuracy: 0.9813: 0s - loss: 0.0641 - sparse_categorical_acc\n",
      "Epoch 16/25\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0705 - sparse_categorical_accuracy: 0.9822\n",
      "Epoch 17/25\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0669 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 18/25\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9868: 2s - loss: 0.0639 - spar\n",
      "Epoch 19/25\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0625 - sparse_categorical_accuracy: 0.9861\n",
      "Epoch 20/25\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0872 - sparse_categorical_accuracy: 0.9850: 0s - loss: 0.0849 - sparse_categorical_accuracy: 0.98\n",
      "Epoch 21/25\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0534 - sparse_categorical_accuracy: 0.9872\n",
      "Epoch 22/25\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0493 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 23/25\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0581 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 24/25\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0799 - sparse_categorical_accuracy: 0.9885\n",
      "Epoch 25/25\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9908: 1s - loss: 0.0365 - sparse_categorica\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 4.8779 - sparse_categorical_accuracy: 0.6667\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/26\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 1.0781 - sparse_categorical_accuracy: 0.5529\n",
      "Epoch 2/26\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6295 - sparse_categorical_accuracy: 0.7599\n",
      "Epoch 3/26\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4797 - sparse_categorical_accuracy: 0.8196\n",
      "Epoch 4/26\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3923 - sparse_categorical_accuracy: 0.8463\n",
      "Epoch 5/26\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.3313 - sparse_categorical_accuracy: 0.8727\n",
      "Epoch 6/26\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2767 - sparse_categorical_accuracy: 0.8927: 1s - loss: 0.2584 - sparse_categorical_ - ETA: 0s - loss: 0.2652 - sparse_categorical_accuracy - ETA: 0s - loss: 0.2751 - sparse_categorical_accuracy\n",
      "Epoch 7/26\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2296 - sparse_categorical_accuracy: 0.9081\n",
      "Epoch 8/26\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1832 - sparse_categorical_accuracy: 0.9308\n",
      "Epoch 9/26\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1503 - sparse_categorical_accuracy: 0.9443\n",
      "Epoch 10/26\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1277 - sparse_categorical_accuracy: 0.9549\n",
      "Epoch 11/26\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1198 - sparse_categorical_accuracy: 0.9659: 2s - loss: 0.1065 - s\n",
      "Epoch 12/26\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9742\n",
      "Epoch 13/26\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0913 - sparse_categorical_accuracy: 0.9740\n",
      "Epoch 14/26\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0700 - sparse_categorical_accuracy: 0.9786\n",
      "Epoch 15/26\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9832\n",
      "Epoch 16/26\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0652 - sparse_categorical_accuracy: 0.9833\n",
      "Epoch 17/26\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9832\n",
      "Epoch 18/26\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0449 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 19/26\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0362 - sparse_categorical_accuracy: 0.9897\n",
      "Epoch 20/26\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.0483 - sparse_categorical_accuracy: 0.9894\n",
      "Epoch 21/26\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 22/26\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9881: 2s - loss: 0.0\n",
      "Epoch 23/26\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0579 - sparse_categorical_accuracy: 0.9892: 0s - loss: 0.0578 - sparse_categorical_accurac\n",
      "Epoch 24/26\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.0485 - sparse_categorical_accuracy: 0.9903: 2s - loss: 0.0110 - sparse_cat - ETA: 1s - loss: 0.0473 - sparse_categ\n",
      "Epoch 25/26\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0517 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 26/26\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0767 - sparse_categorical_accuracy: 0.9901: 0s - loss: 0.0674 - sparse_categorical_accuracy: 0.\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 6.5798 - sparse_categorical_accuracy: 0.6960\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/27\n",
      "171/171 [==============================] - 5s 31ms/step - loss: 1.0795 - sparse_categorical_accuracy: 0.5505\n",
      "Epoch 2/27\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6556 - sparse_categorical_accuracy: 0.7542\n",
      "Epoch 3/27\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.4961 - sparse_categorical_accuracy: 0.8147\n",
      "Epoch 4/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4124 - sparse_categorical_accuracy: 0.8392\n",
      "Epoch 5/27\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3533 - sparse_categorical_accuracy: 0.8652\n",
      "Epoch 6/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2898 - sparse_categorical_accuracy: 0.8857\n",
      "Epoch 7/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2414 - sparse_categorical_accuracy: 0.9020\n",
      "Epoch 8/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1929 - sparse_categorical_accuracy: 0.9255\n",
      "Epoch 9/27\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1553 - sparse_categorical_accuracy: 0.9401A: 3s - loss: 0.13 - ETA: 0s - loss: 0.1583 - sparse_categorical_accuracy: 0.9 - ETA: 0s - loss: 0.1555 - sparse_categorical_accuracy\n",
      "Epoch 10/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1721 - sparse_categorical_accuracy: 0.9478\n",
      "Epoch 11/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1244 - sparse_categorical_accuracy: 0.9559\n",
      "Epoch 12/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1091 - sparse_categorical_accuracy: 0.9647: 2s - loss: 0.\n",
      "Epoch 13/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0875 - sparse_categorical_accuracy: 0.9694: 1s - loss: 0.0750 - sparse_categoric\n",
      "Epoch 14/27\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9793\n",
      "Epoch 15/27\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0631 - sparse_categorical_accuracy: 0.9789: 2s - loss: 0.0617 - sparse_categorical_accuracy: 0 - ETA: 2s - loss: 0.060\n",
      "Epoch 16/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0738 - sparse_categorical_accuracy: 0.9815\n",
      "Epoch 17/27\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0877 - sparse_categorical_accuracy: 0.9808\n",
      "Epoch 18/27\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0863 - sparse_categorical_accuracy: 0.9875: 1s - loss: 0.0511 - sparse_categ - ETA: 0s - loss: 0.0897 - sparse_categorical_accuracy: 0.98 - ETA: 0s - loss: 0.0876 - sparse_categorical_accuracy: 0.987 - ETA: 0s - loss: 0.0861 - sparse_categorical_accuracy: 0.98\n",
      "Epoch 19/27\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9877\n",
      "Epoch 20/27\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0518 - sparse_categorical_accuracy: 0.9855\n",
      "Epoch 21/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0364 - sparse_categorical_accuracy: 0.9894\n",
      "Epoch 22/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0641 - sparse_categorical_accuracy: 0.9886: 1s - loss: 0.0762 - sparse_categoric\n",
      "Epoch 23/27\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0458 - sparse_categorical_accuracy: 0.9921\n",
      "Epoch 24/27\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0858 - sparse_categorical_accuracy: 0.9894\n",
      "Epoch 25/27\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9908ETA: 4s\n",
      "Epoch 26/27\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0506 - sparse_categorical_accuracy: 0.9881: 2s - loss: 0.0306 -\n",
      "Epoch 27/27\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0357 - sparse_categorical_accuracy: 0.9914\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 5.5388 - sparse_categorical_accuracy: 0.6916\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/28\n",
      "171/171 [==============================] - 5s 31ms/step - loss: 1.1635 - sparse_categorical_accuracy: 0.5090\n",
      "Epoch 2/28\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 0.6564 - sparse_categorical_accuracy: 0.7592\n",
      "Epoch 3/28\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 0.4839 - sparse_categorical_accuracy: 0.8187\n",
      "Epoch 4/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4097 - sparse_categorical_accuracy: 0.8410: 1s - loss: 0.3895 - spa\n",
      "Epoch 5/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3431 - sparse_categorical_accuracy: 0.8639\n",
      "Epoch 6/28\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.2860 - sparse_categorical_accuracy: 0.8872\n",
      "Epoch 7/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2350 - sparse_categorical_accuracy: 0.9057\n",
      "Epoch 8/28\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1843 - sparse_categorical_accuracy: 0.9295\n",
      "Epoch 9/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1512 - sparse_categorical_accuracy: 0.9436\n",
      "Epoch 10/28\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1202 - sparse_categorical_accuracy: 0.9566: 3s - \n",
      "Epoch 11/28\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9676\n",
      "Epoch 12/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0883 - sparse_categorical_accuracy: 0.9747\n",
      "Epoch 13/28\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0638 - sparse_categorical_accuracy: 0.9777: 0s - loss: 0.0628 - sparse_categorical_accura\n",
      "Epoch 14/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9822: 1s - loss: 0.0357 - sparse_categorical_accuracy:  - ETA: 1s - loss: 0.0412 - sparse_\n",
      "Epoch 15/28\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0726 - sparse_categorical_accuracy: 0.9830: 2s - loss: 0.0421 - sparse_categorical_accuracy:  - ETA: 1s - loss: 0.0720 - sparse_\n",
      "Epoch 16/28\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0537 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 17/28\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0474 - sparse_categorical_accuracy: 0.9896: 3\n",
      "Epoch 18/28\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 19/28\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0431 - sparse_categorical_accuracy: 0.9892: 0s - loss: 0.0423 - sparse_categorical_accu\n",
      "Epoch 20/28\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1062 - sparse_categorical_accuracy: 0.9855: 0s - loss: 0.1074 - sparse_categorical_accurac\n",
      "Epoch 21/28\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0928 - sparse_categorical_accuracy: 0.9883\n",
      "Epoch 22/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 23/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9907: 0s - loss: 0.0593 - sparse_categorical_accur\n",
      "Epoch 24/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9908\n",
      "Epoch 25/28\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0350 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 26/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 27/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 28/28\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9905\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 3.4537 - sparse_categorical_accuracy: 0.6908\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/29\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 1.1273 - sparse_categorical_accuracy: 0.5383\n",
      "Epoch 2/29\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6507 - sparse_categorical_accuracy: 0.7527\n",
      "Epoch 3/29\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4865 - sparse_categorical_accuracy: 0.8178\n",
      "Epoch 4/29\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4024 - sparse_categorical_accuracy: 0.8458\n",
      "Epoch 5/29\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.3378 - sparse_categorical_accuracy: 0.8665\n",
      "Epoch 6/29\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2793 - sparse_categorical_accuracy: 0.8912\n",
      "Epoch 7/29\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2239 - sparse_categorical_accuracy: 0.9125\n",
      "Epoch 8/29\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1901 - sparse_categorical_accuracy: 0.9240\n",
      "Epoch 9/29\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.1598 - sparse_categorical_accuracy: 0.9414\n",
      "Epoch 10/29\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.1317 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 11/29\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.9626\n",
      "Epoch 12/29\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1088 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 13/29\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0984 - sparse_categorical_accuracy: 0.9707: 0s - loss: 0.0893 - sparse_categorical_ac\n",
      "Epoch 14/29\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 15/29\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9795\n",
      "Epoch 16/29\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9828: 2s - loss:\n",
      "Epoch 17/29\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0541 - sparse_categorical_accuracy: 0.9841: 3s - \n",
      "Epoch 18/29\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9852\n",
      "Epoch 19/29\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0469 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 20/29\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.9875\n",
      "Epoch 21/29\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9872\n",
      "Epoch 22/29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9872\n",
      "Epoch 23/29\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0698 - sparse_categorical_accuracy: 0.9877\n",
      "Epoch 24/29\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0905 - sparse_categorical_accuracy: 0.9894: 1s - loss: 0.1274 - sparse_categorical_accuracy:  - ETA: 1s - loss: 0.1022 - sparse_catego\n",
      "Epoch 25/29\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0566 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 26/29\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0632 - sparse_categorical_accuracy: 0.9894- ETA: 3s - loss: 0.0238 - sparse_categorical_accuracy: 0.98 - ETA: 3s \n",
      "Epoch 27/29\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0885 - sparse_categorical_accuracy: 0.9844: 0s - loss: 0.0855 - sparse_categorical_acc\n",
      "Epoch 28/29\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.0410 - sparse_categorical_accuracy: 0.9883\n",
      "Epoch 29/29\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9918- ETA: 3s - loss: 0.0057 - sparse_categorical_a - ETA: 2s - loss: 0.0220\n",
      "43/43 [==============================] - 0s 12ms/step - loss: 4.5481 - sparse_categorical_accuracy: 0.6864\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/30\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 1.1146 - sparse_categorical_accuracy: 0.5447\n",
      "Epoch 2/30\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6188 - sparse_categorical_accuracy: 0.7683\n",
      "Epoch 3/30\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.4677 - sparse_categorical_accuracy: 0.8194\n",
      "Epoch 4/30\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3921 - sparse_categorical_accuracy: 0.8527: 2s - loss: 0.37\n",
      "Epoch 5/30\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.3301 - sparse_categorical_accuracy: 0.8716\n",
      "Epoch 6/30\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2834 - sparse_categorical_accuracy: 0.8835\n",
      "Epoch 7/30\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.2283 - sparse_categorical_accuracy: 0.9086\n",
      "Epoch 8/30\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1906 - sparse_categorical_accuracy: 0.9306: 1s - loss: 0.1963 - sparse_catego\n",
      "Epoch 9/30\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1687 - sparse_categorical_accuracy: 0.9401\n",
      "Epoch 10/30\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1175 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 11/30\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1031 - sparse_categorical_accuracy: 0.9634\n",
      "Epoch 12/30\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1277 - sparse_categorical_accuracy: 0.9672: 0s - loss: 0.1006 - sparse_categorical_acc\n",
      "Epoch 13/30\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9745\n",
      "Epoch 14/30\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0885 - sparse_categorical_accuracy: 0.9789\n",
      "Epoch 15/30\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9802\n",
      "Epoch 16/30\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0694 - sparse_categorical_accuracy: 0.9815\n",
      "Epoch 17/30\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0652 - sparse_categorical_accuracy: 0.9844\n",
      "Epoch 18/30\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0861 - sparse_categorical_accuracy: 0.9839\n",
      "Epoch 19/30\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9875\n",
      "Epoch 20/30\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0511 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 21/30\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9877: 1s - loss: 0.0401 -\n",
      "Epoch 22/30\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 23/30\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9903\n",
      "Epoch 24/30\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0771 - sparse_categorical_accuracy: 0.9864\n",
      "Epoch 25/30\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1349 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 26/30\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 27/30\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0590 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 28/30\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9918: 0s - loss: 0.0250 - sparse_categorical\n",
      "Epoch 29/30\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0528 - sparse_categorical_accuracy: 0.9919\n",
      "Epoch 30/30\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0493 - sparse_categorical_accuracy: 0.9936: 2s - loss:\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 6.3452 - sparse_categorical_accuracy: 0.6857\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/31\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 1.0848 - sparse_categorical_accuracy: 0.5476\n",
      "Epoch 2/31\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6493 - sparse_categorical_accuracy: 0.7502\n",
      "Epoch 3/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4946 - sparse_categorical_accuracy: 0.8152\n",
      "Epoch 4/31\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4023 - sparse_categorical_accuracy: 0.8456\n",
      "Epoch 5/31\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.3354 - sparse_categorical_accuracy: 0.8687\n",
      "Epoch 6/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2699 - sparse_categorical_accuracy: 0.8925\n",
      "Epoch 7/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2284 - sparse_categorical_accuracy: 0.9099\n",
      "Epoch 8/31\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1875 - sparse_categorical_accuracy: 0.9293\n",
      "Epoch 9/31\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1617 - sparse_categorical_accuracy: 0.9372\n",
      "Epoch 10/31\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1428 - sparse_categorical_accuracy: 0.9509\n",
      "Epoch 11/31\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1236 - sparse_categorical_accuracy: 0.9614\n",
      "Epoch 12/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1212 - sparse_categorical_accuracy: 0.9637\n",
      "Epoch 13/31\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1086 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 14/31\n",
      "171/171 [==============================] - 4s 20ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9753\n",
      "Epoch 15/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9795\n",
      "Epoch 16/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1177 - sparse_categorical_accuracy: 0.9806: 3s - los\n",
      "Epoch 17/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0647 - sparse_categorical_accuracy: 0.9822\n",
      "Epoch 18/31\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0514 - sparse_categorical_accuracy: 0.9894\n",
      "Epoch 19/31\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0548 - sparse_categorical_accuracy: 0.9863\n",
      "Epoch 20/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0487 - sparse_categorical_accuracy: 0.9877\n",
      "Epoch 21/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0648 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 22/31\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 23/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 24/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0773 - sparse_categorical_accuracy: 0.9897: 0s - loss: 0.0831 - sparse_categorical_accuracy:\n",
      "Epoch 25/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9885\n",
      "Epoch 26/31\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0340 - sparse_categorical_accuracy: 0.9903: 1s - loss: 0.0312 - sparse_categorical_accu - ETA: 0s - loss: 0.0297 - sparse_categorical_\n",
      "Epoch 27/31\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0379 - sparse_categorical_accuracy: 0.9903: 0s - loss: 0.0382 - sparse_categorical_accuracy: 0\n",
      "Epoch 28/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0461 - sparse_categorical_accuracy: 0.9918\n",
      "Epoch 29/31\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0636 - sparse_categorical_accuracy: 0.9923\n",
      "Epoch 30/31\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0385 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 31/31\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0491 - sparse_categorical_accuracy: 0.9916: 1s - loss: 0.0268 - sparse_categ\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 5.8258 - sparse_categorical_accuracy: 0.7055\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/32\n",
      "171/171 [==============================] - 5s 27ms/step - loss: 1.0586 - sparse_categorical_accuracy: 0.5711\n",
      "Epoch 2/32\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6012 - sparse_categorical_accuracy: 0.7692: 1s - loss: 0.5925 - sparse_categori\n",
      "Epoch 3/32\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4616 - sparse_categorical_accuracy: 0.8220: 3s - loss\n",
      "Epoch 4/32\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3921 - sparse_categorical_accuracy: 0.8456\n",
      "Epoch 5/32\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3185 - sparse_categorical_accuracy: 0.8736\n",
      "Epoch 6/32\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2661 - sparse_categorical_accuracy: 0.8947\n",
      "Epoch 7/32\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2171 - sparse_categorical_accuracy: 0.9095\n",
      "Epoch 8/32\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1740 - sparse_categorical_accuracy: 0.9341\n",
      "Epoch 9/32\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1384 - sparse_categorical_accuracy: 0.9447\n",
      "Epoch 10/32\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1183 - sparse_categorical_accuracy: 0.9568\n",
      "Epoch 11/32\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1058 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 12/32\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0815 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 13/32\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9773\n",
      "Epoch 14/32\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9782\n",
      "Epoch 15/32\n",
      "171/171 [==============================] - 4s 26ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9797\n",
      "Epoch 16/32\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.0620 - sparse_categorical_accuracy: 0.9842\n",
      "Epoch 17/32\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.0638 - sparse_categorical_accuracy: 0.9852\n",
      "Epoch 18/32\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9870: 2s - loss: 0.0354 - \n",
      "Epoch 19/32\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0703 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 20/32\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0558 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 21/32\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1174 - sparse_categorical_accuracy: 0.9857\n",
      "Epoch 22/32\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1556 - sparse_categorical_accuracy: 0.9875\n",
      "Epoch 23/32\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9890: 1s - loss: 0.0545 - sparse_cat\n",
      "Epoch 24/32\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9908\n",
      "Epoch 25/32\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.0508 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 26/32\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0444 - sparse_categorical_accuracy: 0.9903\n",
      "Epoch 27/32\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0626 - sparse_categorical_accuracy: 0.9903\n",
      "Epoch 28/32\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0536 - sparse_categorical_accuracy: 0.9912: 1s - loss: 0.0624 - sparse_cat\n",
      "Epoch 29/32\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9907: 2s - loss: 0.0306 - \n",
      "Epoch 30/32\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0524 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 31/32\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0377 - sparse_categorical_accuracy: 0.9929: 2s - loss:\n",
      "Epoch 32/32\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0417 - sparse_categorical_accuracy: 0.9925\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 5.1489 - sparse_categorical_accuracy: 0.6901\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/33\n",
      "171/171 [==============================] - 5s 27ms/step - loss: 1.0657 - sparse_categorical_accuracy: 0.5603\n",
      "Epoch 2/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6216 - sparse_categorical_accuracy: 0.7628: 1s - loss: 0.5993 - sparse_categoric\n",
      "Epoch 3/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4710 - sparse_categorical_accuracy: 0.8238\n",
      "Epoch 4/33\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3877 - sparse_categorical_accuracy: 0.8493\n",
      "Epoch 5/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3209 - sparse_categorical_accuracy: 0.8696\n",
      "Epoch 6/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2766 - sparse_categorical_accuracy: 0.8930\n",
      "Epoch 7/33\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2279 - sparse_categorical_accuracy: 0.9137\n",
      "Epoch 8/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1852 - sparse_categorical_accuracy: 0.9275\n",
      "Epoch 9/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1687 - sparse_categorical_accuracy: 0.9432\n",
      "Epoch 10/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1332 - sparse_categorical_accuracy: 0.9478: 1s - loss: 0.1176 - spars\n",
      "Epoch 11/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1242 - sparse_categorical_accuracy: 0.9593: 1s - loss: 0.1228 - sparse_ca\n",
      "Epoch 12/33\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0922 - sparse_categorical_accuracy: 0.9689\n",
      "Epoch 13/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0906 - sparse_categorical_accuracy: 0.9745: 1s - loss: 0.0881 - sparse_categ\n",
      "Epoch 14/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9762: 0s - loss: 0.0768 - sparse_categorical_accuracy:\n",
      "Epoch 15/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0747 - sparse_categorical_accuracy: 0.9802\n",
      "Epoch 16/33\n",
      "171/171 [==============================] - 4s 20ms/step - loss: 0.0739 - sparse_categorical_accuracy: 0.9793\n",
      "Epoch 17/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0621 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 18/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0560 - sparse_categorical_accuracy: 0.9844: 1s - loss: 0.0522 - sp\n",
      "Epoch 19/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9844\n",
      "Epoch 20/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0702 - sparse_categorical_accuracy: 0.9855\n",
      "Epoch 21/33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0572 - sparse_categorical_accuracy: 0.9868\n",
      "Epoch 22/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9879: 0s - loss: 0.0619 - sparse_categorical_a\n",
      "Epoch 23/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0531 - sparse_categorical_accuracy: 0.9886: 2s - loss: 0.0439 - \n",
      "Epoch 24/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0608 - sparse_categorical_accuracy: 0.9886\n",
      "Epoch 25/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 26/33\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 27/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 28/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0662 - sparse_categorical_accuracy: 0.9877\n",
      "Epoch 29/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9903\n",
      "Epoch 30/33\n",
      "171/171 [==============================] - 4s 20ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9932: 0s - loss: 0.0353 - sparse_categorical_accuracy: 0.993\n",
      "Epoch 31/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9932\n",
      "Epoch 32/33\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0716 - sparse_categorical_accuracy: 0.9912: 0s - loss: 0.0779 - sparse_categorical_accur\n",
      "Epoch 33/33\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9897\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 5.2207 - sparse_categorical_accuracy: 0.6711\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/34\n",
      "171/171 [==============================] - 5s 31ms/step - loss: 1.1055 - sparse_categorical_accuracy: 0.5451\n",
      "Epoch 2/34\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6382 - sparse_categorical_accuracy: 0.7636\n",
      "Epoch 3/34\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 0.4902 - sparse_categorical_accuracy: 0.8141\n",
      "Epoch 4/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3936 - sparse_categorical_accuracy: 0.8478\n",
      "Epoch 5/34\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.3252 - sparse_categorical_accuracy: 0.8725\n",
      "Epoch 6/34\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.2541 - sparse_categorical_accuracy: 0.8963\n",
      "Epoch 7/34\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.9114\n",
      "Epoch 8/34\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1878 - sparse_categorical_accuracy: 0.9335\n",
      "Epoch 9/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1551 - sparse_categorical_accuracy: 0.9429\n",
      "Epoch 10/34\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1620 - sparse_categorical_accuracy: 0.9476\n",
      "Epoch 11/34\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1232 - sparse_categorical_accuracy: 0.9593\n",
      "Epoch 12/34\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1023 - sparse_categorical_accuracy: 0.9674\n",
      "Epoch 13/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1055 - sparse_categorical_accuracy: 0.9714\n",
      "Epoch 14/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1005 - sparse_categorical_accuracy: 0.9734\n",
      "Epoch 15/34\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0725 - sparse_categorical_accuracy: 0.9778\n",
      "Epoch 16/34\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1267 - sparse_categorical_accuracy: 0.9782\n",
      "Epoch 17/34\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9802\n",
      "Epoch 18/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0649 - sparse_categorical_accuracy: 0.9826: 3s \n",
      "Epoch 19/34\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9828\n",
      "Epoch 20/34\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0462 - sparse_categorical_accuracy: 0.9875: 0s - loss: 0.0407 - sparse_categorical_accuracy:\n",
      "Epoch 21/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0454 - sparse_categorical_accuracy: 0.9885\n",
      "Epoch 22/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0383 - sparse_categorical_accuracy: 0.9894\n",
      "Epoch 23/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0551 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 24/34\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0522 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 25/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0414 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 26/34\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9903: 1s - loss: 0.0316 - sparse_categor\n",
      "Epoch 27/34\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 28/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0441 - sparse_categorical_accuracy: 0.9921\n",
      "Epoch 29/34\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0461 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 30/34\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0540 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 31/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0518 - sparse_categorical_accuracy: 0.9927\n",
      "Epoch 32/34\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0712 - sparse_categorical_accuracy: 0.9932\n",
      "Epoch 33/34\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0579 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 34/34\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0467 - sparse_categorical_accuracy: 0.9901\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 7.1328 - sparse_categorical_accuracy: 0.6747\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/35\n",
      "171/171 [==============================] - 5s 27ms/step - loss: 1.0682 - sparse_categorical_accuracy: 0.5606\n",
      "Epoch 2/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6174 - sparse_categorical_accuracy: 0.7661\n",
      "Epoch 3/35\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4747 - sparse_categorical_accuracy: 0.8165\n",
      "Epoch 4/35\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.3911 - sparse_categorical_accuracy: 0.8394\n",
      "Epoch 5/35\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3365 - sparse_categorical_accuracy: 0.8667: 2s - los\n",
      "Epoch 6/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2738 - sparse_categorical_accuracy: 0.8881: 2s - loss: 0.2320 \n",
      "Epoch 7/35\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.2231 - sparse_categorical_accuracy: 0.908 - 3s 18ms/step - loss: 0.2215 - sparse_categorical_accuracy: 0.9088\n",
      "Epoch 8/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1858 - sparse_categorical_accuracy: 0.9289\n",
      "Epoch 9/35\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1448 - sparse_categorical_accuracy: 0.9418\n",
      "Epoch 10/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1360 - sparse_categorical_accuracy: 0.9573\n",
      "Epoch 11/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1250 - sparse_categorical_accuracy: 0.9639: 0s - loss: 0.1287 - sparse_categorical_accuracy\n",
      "Epoch 12/35\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0990 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 13/35\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0847 - sparse_categorical_accuracy: 0.9784: 2s - loss: 0.0789 - s - ETA: 0s - loss: 0.0866 - sparse_categorical_accuracy:\n",
      "Epoch 14/35\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0636 - sparse_categorical_accuracy: 0.9815: 1s - loss: 0.0720 - sparse_cate\n",
      "Epoch 15/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0542 - sparse_categorical_accuracy: 0.9826: 0s - loss: 0.0521 - sparse_categorical_accur\n",
      "Epoch 16/35\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9828\n",
      "Epoch 17/35\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9833\n",
      "Epoch 18/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9835: 1s - loss: 0.0592 - sparse\n",
      "Epoch 19/35\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 20/35\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0859 - sparse_categorical_accuracy: 0.9877: 0s - loss: 0.0577 - sparse_categorical_accu\n",
      "Epoch 21/35\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0897 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 22/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9875: 0s - loss: 0.0657 - sparse_categorical_accura\n",
      "Epoch 23/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0686 - sparse_categorical_accuracy: 0.9848\n",
      "Epoch 24/35\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9872\n",
      "Epoch 25/35\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0650 - sparse_categorical_accuracy: 0.9886: 0s - loss: 0.0667 - sparse_categorical_accuracy: \n",
      "Epoch 26/35\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9886\n",
      "Epoch 27/35\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0686 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 28/35\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0724 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 29/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1077 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 30/35\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9901: 0s - loss: 0.0683 - sparse_categorical_accuracy\n",
      "Epoch 31/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 32/35\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 33/35\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9881\n",
      "Epoch 34/35\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1088 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 35/35\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9890\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 5.9863 - sparse_categorical_accuracy: 0.6901\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/36\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 1.1658 - sparse_categorical_accuracy: 0.5383\n",
      "Epoch 2/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6511 - sparse_categorical_accuracy: 0.7579: 0s - loss: 0.6433 - sparse_categorical_accuracy:\n",
      "Epoch 3/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4745 - sparse_categorical_accuracy: 0.8209: 2s - loss: 0.4431 - \n",
      "Epoch 4/36\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4000 - sparse_categorical_accuracy: 0.8449\n",
      "Epoch 5/36\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3267 - sparse_categorical_accuracy: 0.8696\n",
      "Epoch 6/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2738 - sparse_categorical_accuracy: 0.8938\n",
      "Epoch 7/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2221 - sparse_categorical_accuracy: 0.9132\n",
      "Epoch 8/36\n",
      "171/171 [==============================] - 4s 20ms/step - loss: 0.1833 - sparse_categorical_accuracy: 0.9289\n",
      "Epoch 9/36\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1599 - sparse_categorical_accuracy: 0.9412\n",
      "Epoch 10/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1359 - sparse_categorical_accuracy: 0.9544: 2s - loss: 0.1360 - sparse_categorica - ETA: 1s - loss: 0.1312 - sparse_categ\n",
      "Epoch 11/36\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1228 - sparse_categorical_accuracy: 0.9597\n",
      "Epoch 12/36\n",
      "171/171 [==============================] - 4s 20ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9647\n",
      "Epoch 13/36\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9731\n",
      "Epoch 14/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1242 - sparse_categorical_accuracy: 0.9753: 2s - loss: 0.0724 - sparse\n",
      "Epoch 15/36\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0824 - sparse_categorical_accuracy: 0.9784\n",
      "Epoch 16/36\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0893 - sparse_categorical_accuracy: 0.9788\n",
      "Epoch 17/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0893 - sparse_categorical_accuracy: 0.9806\n",
      "Epoch 18/36\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9839\n",
      "Epoch 19/36\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0801 - sparse_categorical_accuracy: 0.9874\n",
      "Epoch 20/36\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0568 - sparse_categorical_accuracy: 0.9874: 0s - loss: 0.0568 - sparse_categorical_accuracy: 0.987\n",
      "Epoch 21/36\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0636 - sparse_categorical_accuracy: 0.9844: 1s - loss: 0.0358 -\n",
      "Epoch 22/36\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0571 - sparse_categorical_accuracy: 0.9855\n",
      "Epoch 23/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0403 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 24/36\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9894\n",
      "Epoch 25/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0791 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 26/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3188 - sparse_categorical_accuracy: 0.9875\n",
      "Epoch 27/36\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 28/36\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0430 - sparse_categorical_accuracy: 0.9908\n",
      "Epoch 29/36\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0529 - sparse_categorical_accuracy: 0.9901\n",
      "Epoch 30/36\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 31/36\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9886: 2s - lo\n",
      "Epoch 32/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0746 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 33/36\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 34/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0577 - sparse_categorical_accuracy: 0.9923: 0s - loss: 0.0587 - sparse_categorical_accuracy: \n",
      "Epoch 35/36\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0423 - sparse_categorical_accuracy: 0.9921\n",
      "Epoch 36/36\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0501 - sparse_categorical_accuracy: 0.9905\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 4.2824 - sparse_categorical_accuracy: 0.6864\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/37\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 1.0868 - sparse_categorical_accuracy: 0.5432\n",
      "Epoch 2/37\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6607 - sparse_categorical_accuracy: 0.7526\n",
      "Epoch 3/37\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.5035 - sparse_categorical_accuracy: 0.8117: 1s - loss: 0.4767 - sparse_\n",
      "Epoch 4/37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 4s 21ms/step - loss: 0.4130 - sparse_categorical_accuracy: 0.8454\n",
      "Epoch 5/37\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3541 - sparse_categorical_accuracy: 0.8683\n",
      "Epoch 6/37\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2929 - sparse_categorical_accuracy: 0.8886: 2s - loss\n",
      "Epoch 7/37\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2377 - sparse_categorical_accuracy: 0.9090: 1s - loss: 0.2292 - sparse\n",
      "Epoch 8/37\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1985 - sparse_categorical_accuracy: 0.9258\n",
      "Epoch 9/37\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1642 - sparse_categorical_accuracy: 0.9379: 3s - loss: 0.\n",
      "Epoch 10/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9511\n",
      "Epoch 11/37\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1236 - sparse_categorical_accuracy: 0.9577\n",
      "Epoch 12/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1126 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 13/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0869 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 14/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0878 - sparse_categorical_accuracy: 0.9786: 4s - \n",
      "Epoch 15/37\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0627 - sparse_categorical_accuracy: 0.9811\n",
      "Epoch 16/37\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1117 - sparse_categorical_accuracy: 0.9850\n",
      "Epoch 17/37\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0577 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 18/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0506 - sparse_categorical_accuracy: 0.9844- ETA: 3\n",
      "Epoch 19/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9850\n",
      "Epoch 20/37\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9864\n",
      "Epoch 21/37\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0851 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 22/37\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.9886\n",
      "Epoch 23/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0684 - sparse_categorical_accuracy: 0.9881\n",
      "Epoch 24/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0496 - sparse_categorical_accuracy: 0.9885: 0s - loss: 0.0526 - sparse_categorical_accur\n",
      "Epoch 25/37\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0653 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 26/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0578 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 27/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1464 - sparse_categorical_accuracy: 0.9894\n",
      "Epoch 28/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9897\n",
      "Epoch 29/37\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9886\n",
      "Epoch 30/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0407 - sparse_categorical_accuracy: 0.9927\n",
      "Epoch 31/37\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1171 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 32/37\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9919\n",
      "Epoch 33/37\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0587 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 34/37\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0509 - sparse_categorical_accuracy: 0.9918: 4s - loss: 0.0109 - sparse_categori - ETA: 1s - loss: 0.0420 - spa\n",
      "Epoch 35/37\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9903: 0s - loss: 0.0517 - sparse_categorical_accuracy: 0 - ETA: 0s - loss: 0.0575 - sparse_categorical_accuracy:\n",
      "Epoch 36/37\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0410 - sparse_categorical_accuracy: 0.9929\n",
      "Epoch 37/37\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0500 - sparse_categorical_accuracy: 0.9927\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 5.3541 - sparse_categorical_accuracy: 0.6901\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/38\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 1.0966 - sparse_categorical_accuracy: 0.5480\n",
      "Epoch 2/38\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6288 - sparse_categorical_accuracy: 0.7612\n",
      "Epoch 3/38\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.4755 - sparse_categorical_accuracy: 0.8284\n",
      "Epoch 4/38\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4034 - sparse_categorical_accuracy: 0.8467\n",
      "Epoch 5/38\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3478 - sparse_categorical_accuracy: 0.8663\n",
      "Epoch 6/38\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2894 - sparse_categorical_accuracy: 0.8912\n",
      "Epoch 7/38\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2440 - sparse_categorical_accuracy: 0.9097\n",
      "Epoch 8/38\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1987 - sparse_categorical_accuracy: 0.9277: 0s - loss: 0.1957 - sparse_categorical_accur\n",
      "Epoch 9/38\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1571 - sparse_categorical_accuracy: 0.9421\n",
      "Epoch 10/38\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1363 - sparse_categorical_accuracy: 0.9529\n",
      "Epoch 11/38\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9584\n",
      "Epoch 12/38\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1029 - sparse_categorical_accuracy: 0.9661\n",
      "Epoch 13/38\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0885 - sparse_categorical_accuracy: 0.9725\n",
      "Epoch 14/38\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0867 - sparse_categorical_accuracy: 0.9769\n",
      "Epoch 15/38\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0684 - sparse_categorical_accuracy: 0.9819: 1s - loss: 0.0550 - spa\n",
      "Epoch 16/38\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9828\n",
      "Epoch 17/38\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1468 - sparse_categorical_accuracy: 0.9821\n",
      "Epoch 18/38\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9868\n",
      "Epoch 19/38\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0627 - sparse_categorical_accuracy: 0.9857\n",
      "Epoch 20/38\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0655 - sparse_categorical_accuracy: 0.9864\n",
      "Epoch 21/38\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0474 - sparse_categorical_accuracy: 0.9888A: \n",
      "Epoch 22/38\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0468 - sparse_categorical_accuracy: 0.9901\n",
      "Epoch 23/38\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0496 - sparse_categorical_accuracy: 0.9919\n",
      "Epoch 24/38\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0315 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 25/38\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0466 - sparse_categorical_accuracy: 0.9908\n",
      "Epoch 26/38\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0397 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 27/38\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 28/38\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0419 - sparse_categorical_accuracy: 0.9929\n",
      "Epoch 29/38\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0588 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 30/38\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0609 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 31/38\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0664 - sparse_categorical_accuracy: 0.9923\n",
      "Epoch 32/38\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0337 - sparse_categorical_accuracy: 0.9934\n",
      "Epoch 33/38\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1004 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 34/38\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9941\n",
      "Epoch 35/38\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9908\n",
      "Epoch 36/38\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0782 - sparse_categorical_accuracy: 0.9914- ETA: 4s - loss: 6.2016e-04 - sparse_categorical_accuracy:  - ETA: 3s - loss\n",
      "Epoch 37/38\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9952\n",
      "Epoch 38/38\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9910: 2s - loss: 0.0486 - sparse_categ - ETA: 1s - loss: 0.0676 - sparse_categori\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 5.0520 - sparse_categorical_accuracy: 0.6821\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/39\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 1.1087 - sparse_categorical_accuracy: 0.55293468 - spar - 3\n",
      "Epoch 2/39\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6320 - sparse_categorical_accuracy: 0.7570\n",
      "Epoch 3/39\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4666 - sparse_categorical_accuracy: 0.8251\n",
      "Epoch 4/39\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.3903 - sparse_categorical_accuracy: 0.8484\n",
      "Epoch 5/39\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3208 - sparse_categorical_accuracy: 0.8782: 0s - loss: 0.3164 - sparse_categorical_accuracy:\n",
      "Epoch 6/39\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2620 - sparse_categorical_accuracy: 0.8974\n",
      "Epoch 7/39\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2099 - sparse_categorical_accuracy: 0.9125A: 3s - los - ETA: 0s - loss: 0.2080 - sparse_categorical_accuracy: 0 - ETA: 0s - loss: 0.2099 - sparse_categorical_accuracy: 0.912\n",
      "Epoch 8/39\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1835 - sparse_categorical_accuracy: 0.9280\n",
      "Epoch 9/39\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1468 - sparse_categorical_accuracy: 0.9440\n",
      "Epoch 10/39\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9524\n",
      "Epoch 11/39\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1234 - sparse_categorical_accuracy: 0.9606: 1s - loss: 0.0906 \n",
      "Epoch 12/39\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 13/39\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0963 - sparse_categorical_accuracy: 0.9729: 3s -\n",
      "Epoch 14/39\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9747: 0s - loss: 0.0972 - sparse_categorical_accuracy: \n",
      "Epoch 15/39\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9775: 1s - loss: 0.0775 - sparse_categorical\n",
      "Epoch 16/39\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9821: 0s - loss: 0.1012 - sparse_categorical_accuracy: 0\n",
      "Epoch 17/39\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0540 - sparse_categorical_accuracy: 0.9841: 2s - loss: 0.0532 - sparse_categorical_accuracy: 0.986 - ETA: 2s - loss: 0.0604 -\n",
      "Epoch 18/39\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9821: 2s - loss: 0.0475 - sparse_catego - ETA: 2s - loss: 0.0723 - sparse_\n",
      "Epoch 19/39\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0693 - sparse_categorical_accuracy: 0.9864\n",
      "Epoch 20/39\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1197 - sparse_categorical_accuracy: 0.9837\n",
      "Epoch 21/39\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 22/39\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9837\n",
      "Epoch 23/39\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9872: 1s - loss: 0.0600 - spar\n",
      "Epoch 24/39\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0807 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 25/39\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0851 - sparse_categorical_accuracy: 0.9894: 2s - loss: \n",
      "Epoch 26/39\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0516 - sparse_categorical_accuracy: 0.9879: 0s - loss: 0.0516 - sparse_categorical_accuracy: 0.987\n",
      "Epoch 27/39\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0491 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 28/39\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9886\n",
      "Epoch 29/39\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 30/39\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0599 - sparse_categorical_accuracy: 0.9892: 1s - loss: 0.0701 -\n",
      "Epoch 31/39\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9886\n",
      "Epoch 32/39\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.1134 - sparse_categorical_accuracy: 0.9890: 2s - loss\n",
      "Epoch 33/39\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0558 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 34/39\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1120 - sparse_categorical_accuracy: 0.9897\n",
      "Epoch 35/39\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1043 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 36/39\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9918: 3s - loss: 0.0470 - sparse_catego - ETA: 1s - loss: 0.0534 - sparse\n",
      "Epoch 37/39\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9919\n",
      "Epoch 38/39\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0651 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 39/39\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0607 - sparse_categorical_accuracy: 0.9901\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 6.7884 - sparse_categorical_accuracy: 0.6967\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/40\n",
      "171/171 [==============================] - 6s 32ms/step - loss: 1.0818 - sparse_categorical_accuracy: 0.56060877 - sparse_categorical_accuracy: 0\n",
      "Epoch 2/40\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6368 - sparse_categorical_accuracy: 0.7681\n",
      "Epoch 3/40\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4770 - sparse_categorical_accuracy: 0.8176: 2s - loss: 0.4549 - sparse_categorical_accuracy: 0 - ETA: 2s - loss: 0.4664 - s\n",
      "Epoch 4/40\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.4036 - sparse_categorical_accuracy: 0.8535\n",
      "Epoch 5/40\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.3273 - sparse_categorical_accuracy: 0.8742\n",
      "Epoch 6/40\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.2685 - sparse_categorical_accuracy: 0.8951\n",
      "Epoch 7/40\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.2282 - sparse_categorical_accuracy: 0.9110: 2s - loss: 0.188\n",
      "Epoch 8/40\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1997 - sparse_categorical_accuracy: 0.9291: 1s - loss: 0.2096 - sparse_categorical\n",
      "Epoch 9/40\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1579 - sparse_categorical_accuracy: 0.9425\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1404 - sparse_categorical_accuracy: 0.9566: 2s - loss: 0.1008 - sparse_ - ETA: 0s - loss: 0.1479 - sparse_categorical_\n",
      "Epoch 11/40\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1130 - sparse_categorical_accuracy: 0.9603\n",
      "Epoch 12/40\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1122 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 13/40\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9740: 1s - loss: 0.1136 - spars\n",
      "Epoch 14/40\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0781 - sparse_categorical_accuracy: 0.9780: 1s - loss: 0.0703 - sparse_categor\n",
      "Epoch 15/40\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0813 - sparse_categorical_accuracy: 0.9797A: 4s \n",
      "Epoch 16/40\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0872 - sparse_categorical_accuracy: 0.9795\n",
      "Epoch 17/40\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0669 - sparse_categorical_accuracy: 0.9811: 1s - loss: 0.0408 - sparse_categ - ETA: 0s - loss: 0.0668 - sparse_categorical_accu\n",
      "Epoch 18/40\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9863: 0s - loss: 0.0612 - sparse_categorical_accuracy: \n",
      "Epoch 19/40\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0655 - sparse_categorical_accuracy: 0.9837\n",
      "Epoch 20/40\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9864: 2s - loss: 0.0912\n",
      "Epoch 21/40\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0692 - sparse_categorical_accuracy: 0.9861: 1s - loss: 0.0648 - sparse_c\n",
      "Epoch 22/40\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 0.0880 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 23/40\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.0680 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 24/40\n",
      "171/171 [==============================] - 4s 26ms/step - loss: 0.0627 - sparse_categorical_accuracy: 0.9870: 0s - loss: 0.0612 - sparse_categorical_accuracy: 0.\n",
      "Epoch 25/40\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 0.0508 - sparse_categorical_accuracy: 0.9883\n",
      "Epoch 26/40\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 0.0479 - sparse_categorical_accuracy: 0.9897\n",
      "Epoch 27/40\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0905 - sparse_categorical_accuracy: 0.9885\n",
      "Epoch 28/40\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.0557 - sparse_categorical_accuracy: 0.9874\n",
      "Epoch 29/40\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 30/40\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1372 - sparse_categorical_accuracy: 0.9879: 2s - loss\n",
      "Epoch 31/40\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0537 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 32/40\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0814 - sparse_categorical_accuracy: 0.9923: 0s - loss: 0.0950 - sparse_categorical_accur\n",
      "Epoch 33/40\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0497 - sparse_categorical_accuracy: 0.991 - 4s 21ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9918\n",
      "Epoch 34/40\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.0450 - sparse_categorical_accuracy: 0.9907: 1s - loss: 0.0220 - spar\n",
      "Epoch 35/40\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9908 ETA: 6s\n",
      "Epoch 36/40\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 37/40\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0566 - sparse_categorical_accuracy: 0.9907\n",
      "Epoch 38/40\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 39/40\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0520 - sparse_categorical_accuracy: 0.9907\n",
      "Epoch 40/40\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0515 - sparse_categorical_accuracy: 0.9905\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 7.5282 - sparse_categorical_accuracy: 0.6864\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/41\n",
      "171/171 [==============================] - 6s 33ms/step - loss: 1.1327 - sparse_categorical_accuracy: 0.5458\n",
      "Epoch 2/41\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6615 - sparse_categorical_accuracy: 0.7553\n",
      "Epoch 3/41\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.4989 - sparse_categorical_accuracy: 0.8161\n",
      "Epoch 4/41\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.4047 - sparse_categorical_accuracy: 0.8445: 3s - loss: 0.3665 - sparse_categori - ETA: 1s - loss: 0.3953 - sparse_categorical_accuracy: 0. - ETA: 1s - loss: 0.3951 - sparse_categ\n",
      "Epoch 5/41\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3381 - sparse_categorical_accuracy: 0.8659\n",
      "Epoch 6/41\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.2950 - sparse_categorical_accuracy: 0.8864\n",
      "Epoch 7/41\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2365 - sparse_categorical_accuracy: 0.9049\n",
      "Epoch 8/41\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 0.2095 - sparse_categorical_accuracy: 0.9267: 1s - loss: 0.1924 - sparse_categoric\n",
      "Epoch 9/41\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 0.1568 - sparse_categorical_accuracy: 0.9383: 1s - loss: 0.1446 - sparse_\n",
      "Epoch 10/41\n",
      "171/171 [==============================] - 4s 20ms/step - loss: 0.1356 - sparse_categorical_accuracy: 0.9504\n",
      "Epoch 11/41\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1044 - sparse_categorical_accuracy: 0.9608: 1s - loss: 0.0985 - sparse_categorica\n",
      "Epoch 12/41\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.1102 - sparse_categorical_accuracy: 0.9665: 0s - loss: 0.1123 - sparse_categorical_accuracy\n",
      "Epoch 13/41\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9725\n",
      "Epoch 14/41\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0906 - sparse_categorical_accuracy: 0.9769: 0s - loss: 0.0906 - sparse_categorical_accuracy: 0.977\n",
      "Epoch 15/41\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9782\n",
      "Epoch 16/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9830\n",
      "Epoch 17/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9863: 2s - loss: \n",
      "Epoch 18/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9863\n",
      "Epoch 19/41\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9861\n",
      "Epoch 20/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9883\n",
      "Epoch 21/41\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0500 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 22/41\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0762 - sparse_categorical_accuracy: 0.9896: 2s - loss: 0.0424 - spars\n",
      "Epoch 23/41\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0415 - sparse_categorical_accuracy: 0.9907\n",
      "Epoch 24/41\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9890: 3s - loss: 0\n",
      "Epoch 25/41\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0560 - sparse_categorical_accuracy: 0.9877\n",
      "Epoch 26/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9919\n",
      "Epoch 27/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9897\n",
      "Epoch 28/41\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0381 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 29/41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9897\n",
      "Epoch 30/41\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 31/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0887 - sparse_categorical_accuracy: 0.9921: 2s - loss: 0.\n",
      "Epoch 32/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0517 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 33/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9927\n",
      "Epoch 34/41\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0368 - sparse_categorical_accuracy: 0.9916- ETA: 3s - loss: 7.4\n",
      "Epoch 35/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2037 - sparse_categorical_accuracy: 0.9905: 1s - loss: 0.2943 - sparse_cate\n",
      "Epoch 36/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 37/41\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0542 - sparse_categorical_accuracy: 0.9929\n",
      "Epoch 38/41\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1018 - sparse_categorical_accuracy: 0.9857\n",
      "Epoch 39/41\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9907\n",
      "Epoch 40/41\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9897\n",
      "Epoch 41/41\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0368 - sparse_categorical_accuracy: 0.9925: 2s - loss: 0.0406\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 5.5107 - sparse_categorical_accuracy: 0.6930\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/42\n",
      "171/171 [==============================] - 6s 32ms/step - loss: 1.0939 - sparse_categorical_accuracy: 0.5368\n",
      "Epoch 2/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6471 - sparse_categorical_accuracy: 0.7562\n",
      "Epoch 3/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4897 - sparse_categorical_accuracy: 0.8214\n",
      "Epoch 4/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4087 - sparse_categorical_accuracy: 0.8480\n",
      "Epoch 5/42\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.3453 - sparse_categorical_accuracy: 0.8674\n",
      "Epoch 6/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2804 - sparse_categorical_accuracy: 0.8908\n",
      "Epoch 7/42\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.2234 - sparse_categorical_accuracy: 0.9099: 0s - loss: 0.2146 - sparse_categorical_\n",
      "Epoch 8/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1866 - sparse_categorical_accuracy: 0.9273: 0s - loss: 0.1800 - sparse_categorical_accurac\n",
      "Epoch 9/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1525 - sparse_categorical_accuracy: 0.9436\n",
      "Epoch 10/42\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1256 - sparse_categorical_accuracy: 0.9522\n",
      "Epoch 11/42\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.1286 - sparse_categorical_accuracy: 0.9581\n",
      "Epoch 12/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9637: 1s - loss: 0.1103 - spars\n",
      "Epoch 13/42\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 14/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1221 - sparse_categorical_accuracy: 0.9736\n",
      "Epoch 15/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9777\n",
      "Epoch 16/42\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0676 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 17/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0934 - sparse_categorical_accuracy: 0.9804\n",
      "Epoch 18/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0907 - sparse_categorical_accuracy: 0.9835: 2s - loss: 0.068\n",
      "Epoch 19/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0557 - sparse_categorical_accuracy: 0.9855: 1s - loss: 0.0664 - sparse_categ\n",
      "Epoch 20/42\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9844\n",
      "Epoch 21/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9846: 0s - loss: 0.0680 - sparse_categorical_accura - ETA: 0s - loss: 0.0681 - sparse_categorical_accuracy: 0\n",
      "Epoch 22/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9903\n",
      "Epoch 23/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9890: 2s - loss: 0.0\n",
      "Epoch 24/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9861\n",
      "Epoch 25/42\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9892: 0s - loss: 0.0440 - sparse_categorical_accuracy: 0.99\n",
      "Epoch 26/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0595 - sparse_categorical_accuracy: 0.9910: 0s - loss: 0.0533 - sparse_categorical_accu - ETA: 0s - loss: 0.0550 - sparse_categorical_accuracy: 0.9\n",
      "Epoch 27/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0461 - sparse_categorical_accuracy: 0.9921: 2s - loss: 0.0117 \n",
      "Epoch 28/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0505 - sparse_categorical_accuracy: 0.9901\n",
      "Epoch 29/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0441 - sparse_categorical_accuracy: 0.9919\n",
      "Epoch 30/42\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0339 - sparse_categorical_accuracy: 0.9932\n",
      "Epoch 31/42\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0619 - sparse_categorical_accuracy: 0.9921: 2s - loss: 0.0238 - sparse_categorical_accuracy: 0 - ETA: 2s - loss: 0.0195 \n",
      "Epoch 32/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0322 - sparse_categorical_accuracy: 0.9945\n",
      "Epoch 33/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0342 - sparse_categorical_accuracy: 0.9941\n",
      "Epoch 34/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0355 - sparse_categorical_accuracy: 0.9932A: 3s - loss: 0.0500 - sparse_categ - ETA: 1s - loss: 0.0170 - sparse_\n",
      "Epoch 35/42\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0613 - sparse_categorical_accuracy: 0.9921\n",
      "Epoch 36/42\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0603 - sparse_categorical_accuracy: 0.9918\n",
      "Epoch 37/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0347 - sparse_categorical_accuracy: 0.9930: 1s - loss: 0.0390 - spars\n",
      "Epoch 38/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0336 - sparse_categorical_accuracy: 0.9919: 2s - loss: 0.0242 - sparse_categoric - ETA: 1s - loss: 0.0389 - sparse_categ\n",
      "Epoch 39/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0535 - sparse_categorical_accuracy: 0.9940\n",
      "Epoch 40/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0521 - sparse_categorical_accuracy: 0.9932\n",
      "Epoch 41/42\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9908\n",
      "Epoch 42/42\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1246 - sparse_categorical_accuracy: 0.9930\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 5.1744 - sparse_categorical_accuracy: 0.6791\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/43\n",
      "171/171 [==============================] - 5s 27ms/step - loss: 1.0722 - sparse_categorical_accuracy: 0.5617\n",
      "Epoch 2/43\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6414 - sparse_categorical_accuracy: 0.7551\n",
      "Epoch 3/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4794 - sparse_categorical_accuracy: 0.8209\n",
      "Epoch 4/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3981 - sparse_categorical_accuracy: 0.8458\n",
      "Epoch 5/43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3221 - sparse_categorical_accuracy: 0.8723\n",
      "Epoch 6/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2631 - sparse_categorical_accuracy: 0.8962\n",
      "Epoch 7/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2117 - sparse_categorical_accuracy: 0.9179: 3s - \n",
      "Epoch 8/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1691 - sparse_categorical_accuracy: 0.9352: 0s - loss: 0.1703 - sparse_categorical_accuracy: 0.9\n",
      "Epoch 9/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1724 - sparse_categorical_accuracy: 0.9487\n",
      "Epoch 10/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9570\n",
      "Epoch 11/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1080 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 12/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1037 - sparse_categorical_accuracy: 0.9731: 0s - loss: 0.1015 - sparse_categorical_accuracy: 0.\n",
      "Epoch 13/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0824 - sparse_categorical_accuracy: 0.9753\n",
      "Epoch 14/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0735 - sparse_categorical_accuracy: 0.9784: 0s - loss: 0.0685 - sparse_categorical_acc\n",
      "Epoch 15/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9811\n",
      "Epoch 16/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0664 - sparse_categorical_accuracy: 0.9839\n",
      "Epoch 17/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1198 - sparse_categorical_accuracy: 0.9864\n",
      "Epoch 18/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9863: 2s - loss: 0.042\n",
      "Epoch 19/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9822\n",
      "Epoch 20/43\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0383 - sparse_categorical_accuracy: 0.9896: 3s - loss: \n",
      "Epoch 21/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0642 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 22/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 23/43\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1159 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 24/43\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 25/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0607 - sparse_categorical_accuracy: 0.9912: 1s - loss: 0.0779 - spa\n",
      "Epoch 26/43\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.9919\n",
      "Epoch 27/43\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0431 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 28/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9921: 2s - loss: 0.0547 \n",
      "Epoch 29/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0626 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 30/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0635 - sparse_categorical_accuracy: 0.9899: 2s - loss: 0.0267 - sparse_categorical_accuracy:  - ETA: 2s - loss: 0.0223 - s\n",
      "Epoch 31/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0674 - sparse_categorical_accuracy: 0.9927\n",
      "Epoch 32/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0265 - sparse_categorical_accuracy: 0.9938\n",
      "Epoch 33/43\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0761 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 34/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9907\n",
      "Epoch 35/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0533 - sparse_categorical_accuracy: 0.9908\n",
      "Epoch 36/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0648 - sparse_categorical_accuracy: 0.9897: 1s - loss: 0.0203 - sp\n",
      "Epoch 37/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 38/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0651 - sparse_categorical_accuracy: 0.9927: 1s - loss: 0.0520 - sparse_categori\n",
      "Epoch 39/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1403 - sparse_categorical_accuracy: 0.9908\n",
      "Epoch 40/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9949\n",
      "Epoch 41/43\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9923 ETA: 3s - \n",
      "Epoch 42/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1393 - sparse_categorical_accuracy: 0.9916: 0s - loss: 0.1350 - sparse_categorical_a\n",
      "Epoch 43/43\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0600 - sparse_categorical_accuracy: 0.9934\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 6.2486 - sparse_categorical_accuracy: 0.6784\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/44\n",
      "171/171 [==============================] - 5s 27ms/step - loss: 1.0816 - sparse_categorical_accuracy: 0.5579\n",
      "Epoch 2/44\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6147 - sparse_categorical_accuracy: 0.7670\n",
      "Epoch 3/44\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.4773 - sparse_categorical_accuracy: 0.8227\n",
      "Epoch 4/44\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.3891 - sparse_categorical_accuracy: 0.8487\n",
      "Epoch 5/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3186 - sparse_categorical_accuracy: 0.8729: 1s - loss: 0.2884 - sparse_cat\n",
      "Epoch 6/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2681 - sparse_categorical_accuracy: 0.8890\n",
      "Epoch 7/44\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2210 - sparse_categorical_accuracy: 0.9092\n",
      "Epoch 8/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1798 - sparse_categorical_accuracy: 0.9295\n",
      "Epoch 9/44\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1607 - sparse_categorical_accuracy: 0.9379: 1s - loss: 0.1656 - sparse_categorical\n",
      "Epoch 10/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1373 - sparse_categorical_accuracy: 0.9509A: 3s \n",
      "Epoch 11/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1056 - sparse_categorical_accuracy: 0.9637\n",
      "Epoch 12/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0937 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 13/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9692\n",
      "Epoch 14/44\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9778\n",
      "Epoch 15/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0843 - sparse_categorical_accuracy: 0.9795\n",
      "Epoch 16/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1029 - sparse_categorical_accuracy: 0.9824\n",
      "Epoch 17/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0929 - sparse_categorical_accuracy: 0.9832\n",
      "Epoch 18/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9868\n",
      "Epoch 19/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9839\n",
      "Epoch 20/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0581 - sparse_categorical_accuracy: 0.9864: 0s - loss: 0.0620 - sparse_categorical_accuracy:\n",
      "Epoch 21/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0735 - sparse_categorical_accuracy: 0.9863\n",
      "Epoch 22/44\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0499 - sparse_categorical_accuracy: 0.9894: 1s - loss: 0.0656 - sparse_categorica\n",
      "Epoch 23/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9881: 0s - loss: 0.0597 - sparse_categorical_accuracy: \n",
      "Epoch 24/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0634 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 25/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 26/44\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0558 - sparse_categorical_accuracy: 0.9901: 2s - loss: 0.0621 -\n",
      "Epoch 27/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 28/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0469 - sparse_categorical_accuracy: 0.9912: 2s - loss: 0.0528 - sp\n",
      "Epoch 29/44\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0644 - sparse_categorical_accuracy: 0.9919\n",
      "Epoch 30/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9908\n",
      "Epoch 31/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9896 ETA: 3s - l\n",
      "Epoch 32/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.9918\n",
      "Epoch 33/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0944 - sparse_categorical_accuracy: 0.9897\n",
      "Epoch 34/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0410 - sparse_categorical_accuracy: 0.9929: 0s - loss: 0.0326 - sparse_categorical_accura\n",
      "Epoch 35/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0408 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 36/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9910: 1s - loss: 0.0532 - sparse_\n",
      "Epoch 37/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0383 - sparse_categorical_accuracy: 0.9934\n",
      "Epoch 38/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0520 - sparse_categorical_accuracy: 0.9932\n",
      "Epoch 39/44\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 40/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0728 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 41/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0256 - sparse_categorical_accuracy: 0.9938\n",
      "Epoch 42/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9929: 0s - loss: 0.0508 - sparse_categorical_accuracy: 0.\n",
      "Epoch 43/44\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0684 - sparse_categorical_accuracy: 0.9918\n",
      "Epoch 44/44\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0410 - sparse_categorical_accuracy: 0.9914\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 7.9005 - sparse_categorical_accuracy: 0.6886\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/45\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 1.0781 - sparse_categorical_accuracy: 0.5625\n",
      "Epoch 2/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6341 - sparse_categorical_accuracy: 0.7564\n",
      "Epoch 3/45\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.4792 - sparse_categorical_accuracy: 0.8161\n",
      "Epoch 4/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4015 - sparse_categorical_accuracy: 0.8451\n",
      "Epoch 5/45\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3296 - sparse_categorical_accuracy: 0.8674: 1s - loss: 0.2804 - \n",
      "Epoch 6/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2678 - sparse_categorical_accuracy: 0.8978\n",
      "Epoch 7/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2238 - sparse_categorical_accuracy: 0.9086\n",
      "Epoch 8/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1996 - sparse_categorical_accuracy: 0.9273\n",
      "Epoch 9/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1738 - sparse_categorical_accuracy: 0.9374\n",
      "Epoch 10/45\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1444 - sparse_categorical_accuracy: 0.9487\n",
      "Epoch 11/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1270 - sparse_categorical_accuracy: 0.9573\n",
      "Epoch 12/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1116 - sparse_categorical_accuracy: 0.9617\n",
      "Epoch 13/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0915 - sparse_categorical_accuracy: 0.9705\n",
      "Epoch 14/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0926 - sparse_categorical_accuracy: 0.9734\n",
      "Epoch 15/45\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1134 - sparse_categorical_accuracy: 0.9740\n",
      "Epoch 16/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.9778\n",
      "Epoch 17/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0772 - sparse_categorical_accuracy: 0.9769: 1s - loss: 0.0637 - sparse_categor - ETA: 0s - loss: 0.0723 - sparse_categorical_accuracy\n",
      "Epoch 18/45\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0631 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 19/45\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0665 - sparse_categorical_accuracy: 0.9833: 0s - loss: 0.0670 - sparse_categorical_accu\n",
      "Epoch 20/45\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0529 - sparse_categorical_accuracy: 0.9857\n",
      "Epoch 21/45\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9861\n",
      "Epoch 22/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9879: 1s - loss: 0.0824 - sparse_catego\n",
      "Epoch 23/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0524 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 24/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0439 - sparse_categorical_accuracy: 0.9861: 1s - loss: 0.0407 - sp\n",
      "Epoch 25/45\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0815 - sparse_categorical_accuracy: 0.9846: 0s - loss: 0.0869 - sparse_categorical_accuracy:\n",
      "Epoch 26/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9881\n",
      "Epoch 27/45\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9907\n",
      "Epoch 28/45\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0426 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 29/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0541 - sparse_categorical_accuracy: 0.9894\n",
      "Epoch 30/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9908\n",
      "Epoch 31/45\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0465 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 32/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0455 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 33/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0534 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 34/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0635 - sparse_categorical_accuracy: 0.9910: 1s - loss: 0.0494 - sparse_categorical_accuracy - ETA: 1s - loss: 0.0559 - sparse_categori\n",
      "Epoch 35/45\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9923: 2s - loss: 0.0417 - spa\n",
      "Epoch 36/45\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0247 - sparse_categorical_accuracy: 0.9951\n",
      "Epoch 37/45\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0317 - sparse_categorical_accuracy: 0.9936\n",
      "Epoch 38/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0540 - sparse_categorical_accuracy: 0.9908: 2s - loss: 0\n",
      "Epoch 39/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0658 - sparse_categorical_accuracy: 0.9923: 0s - loss: 0.0450 - sparse_categorical_accuracy:  - ETA: 0s - loss: 0.0740 - sparse_categorical_accuracy:\n",
      "Epoch 40/45\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1482 - sparse_categorical_accuracy: 0.9912: 1s - loss: 0.2135 - sparse_cate\n",
      "Epoch 41/45\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.9940: 3s - loss: \n",
      "Epoch 42/45\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0713 - sparse_categorical_accuracy: 0.9892: 1s - loss: 0.0582 - sp\n",
      "Epoch 43/45\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0438 - sparse_categorical_accuracy: 0.9930: 2s - loss: 0.\n",
      "Epoch 44/45\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2210 - sparse_categorical_accuracy: 0.9883\n",
      "Epoch 45/45\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9936: 1s - loss: 0.0503 - sparse_categoric\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 10.0505 - sparse_categorical_accuracy: 0.6835\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/46\n",
      "171/171 [==============================] - 5s 27ms/step - loss: 1.0706 - sparse_categorical_accuracy: 0.5571\n",
      "Epoch 2/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6103 - sparse_categorical_accuracy: 0.7645\n",
      "Epoch 3/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4693 - sparse_categorical_accuracy: 0.8225\n",
      "Epoch 4/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3876 - sparse_categorical_accuracy: 0.8489\n",
      "Epoch 5/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3276 - sparse_categorical_accuracy: 0.8740\n",
      "Epoch 6/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2636 - sparse_categorical_accuracy: 0.8910\n",
      "Epoch 7/46\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.2211 - sparse_categorical_accuracy: 0.9134\n",
      "Epoch 8/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1804 - sparse_categorical_accuracy: 0.9315\n",
      "Epoch 9/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1475 - sparse_categorical_accuracy: 0.9438\n",
      "Epoch 10/46\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1242 - sparse_categorical_accuracy: 0.9540\n",
      "Epoch 11/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1283 - sparse_categorical_accuracy: 0.9614: 3s - lo\n",
      "Epoch 12/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1195 - sparse_categorical_accuracy: 0.9701: 1s - loss: 0.1302 - sparse_categorical_accuracy: 0.9 - ETA: 1s - loss: 0.1268 - sparse_categori\n",
      "Epoch 13/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9718\n",
      "Epoch 14/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9769: 1s - loss: 0.0648 - sparse_categ\n",
      "Epoch 15/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9800\n",
      "Epoch 16/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9841\n",
      "Epoch 17/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9832: 0s - loss: 0.0695 - sparse_categorical_a\n",
      "Epoch 18/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0682 - sparse_categorical_accuracy: 0.9861\n",
      "Epoch 19/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0770 - sparse_categorical_accuracy: 0.9861\n",
      "Epoch 20/46\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9839: 1s - loss: 0.0691 - sparse_catego\n",
      "Epoch 21/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0477 - sparse_categorical_accuracy: 0.9874\n",
      "Epoch 22/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9857: 1s - loss: 0.1517 - sparse_categorical\n",
      "Epoch 23/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 24/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0656 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 25/46\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0515 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 26/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1561 - sparse_categorical_accuracy: 0.9892: 1s - loss: 0.3017 - spar\n",
      "Epoch 27/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0693 - sparse_categorical_accuracy: 0.9879: 1s - loss: 0.0456 - sparse_categ\n",
      "Epoch 28/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9857\n",
      "Epoch 29/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0580 - sparse_categorical_accuracy: 0.9903\n",
      "Epoch 30/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0921 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 31/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0602 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 32/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0654 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 33/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0419 - sparse_categorical_accuracy: 0.9927\n",
      "Epoch 34/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 35/46\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9885\n",
      "Epoch 36/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 37/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9923\n",
      "Epoch 38/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0506 - sparse_categorical_accuracy: 0.9938\n",
      "Epoch 39/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0631 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 40/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9914: 2s - loss\n",
      "Epoch 41/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1326 - sparse_categorical_accuracy: 0.9934: 2s - loss: \n",
      "Epoch 42/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9940: 2s - loss: 0.0291\n",
      "Epoch 43/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0466 - sparse_categorical_accuracy: 0.9925: 1s - loss: 0.0390 - \n",
      "Epoch 44/46\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0654 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 45/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9899: 1s - loss: 0.0363 - sparse_categorical_accuracy: 0. - ETA: 1s - loss: 0.0331 - sparse_cat\n",
      "Epoch 46/46\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0717 - sparse_categorical_accuracy: 0.9914\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 6.9291 - sparse_categorical_accuracy: 0.6930\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/47\n",
      "171/171 [==============================] - 4s 25ms/step - loss: 1.0625 - sparse_categorical_accuracy: 0.5559\n",
      "Epoch 2/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6283 - sparse_categorical_accuracy: 0.7566\n",
      "Epoch 3/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4716 - sparse_categorical_accuracy: 0.8244\n",
      "Epoch 4/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3807 - sparse_categorical_accuracy: 0.8485\n",
      "Epoch 5/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3302 - sparse_categorical_accuracy: 0.8698\n",
      "Epoch 6/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2653 - sparse_categorical_accuracy: 0.8912\n",
      "Epoch 7/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2196 - sparse_categorical_accuracy: 0.9101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1777 - sparse_categorical_accuracy: 0.9300\n",
      "Epoch 9/47\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1477 - sparse_categorical_accuracy: 0.9451\n",
      "Epoch 10/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1206 - sparse_categorical_accuracy: 0.9586\n",
      "Epoch 11/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1034 - sparse_categorical_accuracy: 0.9654\n",
      "Epoch 12/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0770 - sparse_categorical_accuracy: 0.9751\n",
      "Epoch 13/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9777\n",
      "Epoch 14/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9813: 1s - loss: 0.0722 - sparse_categorica\n",
      "Epoch 15/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0793 - sparse_categorical_accuracy: 0.9835: 0s - loss: 0.0816 - sparse_categorical_accurac\n",
      "Epoch 16/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9848\n",
      "Epoch 17/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0580 - sparse_categorical_accuracy: 0.9848\n",
      "Epoch 18/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0578 - sparse_categorical_accuracy: 0.9872: 0s - loss: 0.0523 - sparse_categorical_acc\n",
      "Epoch 19/47\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 20/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0523 - sparse_categorical_accuracy: 0.9885\n",
      "Epoch 21/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9864: 2s - loss: 0.0\n",
      "Epoch 22/47\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0357 - sparse_categorical_accuracy: 0.9899: 1s - loss: 0.0270 - spars\n",
      "Epoch 23/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 24/47\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0334 - sparse_categorical_accuracy: 0.9910: 0s - loss: 0.0327 - sparse_categorical_accuracy: 0.\n",
      "Epoch 25/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 26/47\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9896- ETA: 3s - lo\n",
      "Epoch 27/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0585 - sparse_categorical_accuracy: 0.9877\n",
      "Epoch 28/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0528 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 29/47\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0359 - sparse_categorical_accuracy: 0.9907\n",
      "Epoch 30/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9907\n",
      "Epoch 31/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 32/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0509 - sparse_categorical_accuracy: 0.9907: 2s - loss: 0.0743 - \n",
      "Epoch 33/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0436 - sparse_categorical_accuracy: 0.9929\n",
      "Epoch 34/47\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0641 - sparse_categorical_accuracy: 0.9927\n",
      "Epoch 35/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0274 - sparse_categorical_accuracy: 0.9947\n",
      "Epoch 36/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0465 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 37/47\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9938\n",
      "Epoch 38/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0773 - sparse_categorical_accuracy: 0.9912: 0s - loss: 0.0742 - sparse_categorical_accura\n",
      "Epoch 39/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0377 - sparse_categorical_accuracy: 0.9941\n",
      "Epoch 40/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0457 - sparse_categorical_accuracy: 0.9918\n",
      "Epoch 41/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0199 - sparse_categorical_accuracy: 0.9943\n",
      "Epoch 42/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0705 - sparse_categorical_accuracy: 0.9929\n",
      "Epoch 43/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9951\n",
      "Epoch 44/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1134 - sparse_categorical_accuracy: 0.9918: 2s - loss: 0.2000 - sparse_categorical_accuracy: 0 - ETA: 2s - loss: 0.1897 - sparse_categorical_accuracy: 0.99 - ETA: 1s - loss: 0.1736 - sp\n",
      "Epoch 45/47\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0402 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 46/47\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0452 - sparse_categorical_accuracy: 0.9932\n",
      "Epoch 47/47\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0721 - sparse_categorical_accuracy: 0.9918\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 8.0769 - sparse_categorical_accuracy: 0.6923\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/48\n",
      "171/171 [==============================] - 4s 26ms/step - loss: 1.1253 - sparse_categorical_accuracy: 0.5293\n",
      "Epoch 2/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6515 - sparse_categorical_accuracy: 0.7579: 1s - loss: 0.6425 - sparse_categorical_acc - ETA: 0s - loss: 0.6490 - sparse_categorical_accuracy: \n",
      "Epoch 3/48\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4787 - sparse_categorical_accuracy: 0.8214: 0s - loss: 0.4736 - sparse_categorical_acc\n",
      "Epoch 4/48\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4037 - sparse_categorical_accuracy: 0.8441\n",
      "Epoch 5/48\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3353 - sparse_categorical_accuracy: 0.8687: 2s - loss: 0.3171 - sparse_cate - ETA: 0s - loss: 0.3331 - sparse_categorical_ac\n",
      "Epoch 6/48\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2793 - sparse_categorical_accuracy: 0.8923\n",
      "Epoch 7/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2189 - sparse_categorical_accuracy: 0.9123\n",
      "Epoch 8/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1916 - sparse_categorical_accuracy: 0.9289\n",
      "Epoch 9/48\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1705 - sparse_categorical_accuracy: 0.9399\n",
      "Epoch 10/48\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1360 - sparse_categorical_accuracy: 0.9471\n",
      "Epoch 11/48\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1211 - sparse_categorical_accuracy: 0.9606\n",
      "Epoch 12/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1007 - sparse_categorical_accuracy: 0.9705\n",
      "Epoch 13/48\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1036 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 14/48\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0717 - sparse_categorical_accuracy: 0.9767\n",
      "Epoch 15/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9769\n",
      "Epoch 16/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0942 - sparse_categorical_accuracy: 0.9804\n",
      "Epoch 17/48\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0772 - sparse_categorical_accuracy: 0.9833\n",
      "Epoch 18/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9826: 1s - loss: 0.0737 - sparse_categoric\n",
      "Epoch 19/48\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0921 - sparse_categorical_accuracy: 0.9821\n",
      "Epoch 20/48\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9859: 2s - loss: 0.0556 - sparse_categorical_accuracy: 0 - ETA: 2s - loss: 0.0492 -\n",
      "Epoch 21/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9852\n",
      "Epoch 22/48\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0575 - sparse_categorical_accuracy: 0.9885: 0s - loss: 0.0506 - sparse_categorical_accur\n",
      "Epoch 23/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1098 - sparse_categorical_accuracy: 0.9863\n",
      "Epoch 24/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9875: 1s - loss: 0.0721 - spar\n",
      "Epoch 25/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 26/48\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1005 - sparse_categorical_accuracy: 0.9864\n",
      "Epoch 27/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0746 - sparse_categorical_accuracy: 0.9886\n",
      "Epoch 28/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9903: 0s - loss: 0.0486 - sparse_categorical_accur\n",
      "Epoch 29/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 30/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 31/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 32/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9894: 2s - loss: 0.06\n",
      "Epoch 33/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0686 - sparse_categorical_accuracy: 0.9881\n",
      "Epoch 34/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9903\n",
      "Epoch 35/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0626 - sparse_categorical_accuracy: 0.9901\n",
      "Epoch 36/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0579 - sparse_categorical_accuracy: 0.9901\n",
      "Epoch 37/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0620 - sparse_categorical_accuracy: 0.9916A: 4\n",
      "Epoch 38/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0533 - sparse_categorical_accuracy: 0.9894\n",
      "Epoch 39/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 40/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0834 - sparse_categorical_accuracy: 0.9885\n",
      "Epoch 41/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0599 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 42/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0460 - sparse_categorical_accuracy: 0.9927\n",
      "Epoch 43/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0874 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 44/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0556 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 45/48\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.9929\n",
      "Epoch 46/48\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0506 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 47/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 48/48\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0621 - sparse_categorical_accuracy: 0.9927\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 8.3487 - sparse_categorical_accuracy: 0.6916\n",
      "lr 0.009000000000000001\n",
      "Epoch 1/49\n",
      "171/171 [==============================] - 6s 36ms/step - loss: 1.0854 - sparse_categorical_accuracy: 0.5509\n",
      "Epoch 2/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6399 - sparse_categorical_accuracy: 0.7617\n",
      "Epoch 3/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4942 - sparse_categorical_accuracy: 0.8150\n",
      "Epoch 4/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4064 - sparse_categorical_accuracy: 0.8445: 2s - loss\n",
      "Epoch 5/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3326 - sparse_categorical_accuracy: 0.8694\n",
      "Epoch 6/49\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2804 - sparse_categorical_accuracy: 0.8901\n",
      "Epoch 7/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2347 - sparse_categorical_accuracy: 0.9070\n",
      "Epoch 8/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1896 - sparse_categorical_accuracy: 0.9264\n",
      "Epoch 9/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1694 - sparse_categorical_accuracy: 0.9372\n",
      "Epoch 10/49\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1354 - sparse_categorical_accuracy: 0.9520\n",
      "Epoch 11/49\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1138 - sparse_categorical_accuracy: 0.9595\n",
      "Epoch 12/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1331 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 13/49\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1037 - sparse_categorical_accuracy: 0.9720: 3s -\n",
      "Epoch 14/49\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9786\n",
      "Epoch 15/49\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9778\n",
      "Epoch 16/49\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9808\n",
      "Epoch 17/49\n",
      "171/171 [==============================] - 5s 26ms/step - loss: 0.0640 - sparse_categorical_accuracy: 0.9824: 3s - loss: 0.0\n",
      "Epoch 18/49\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0878 - sparse_categorical_accuracy: 0.9864\n",
      "Epoch 19/49\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0732 - sparse_categorical_accuracy: 0.9850\n",
      "Epoch 20/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0743 - sparse_categorical_accuracy: 0.9855\n",
      "Epoch 21/49\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9861\n",
      "Epoch 22/49\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0556 - sparse_categorical_accuracy: 0.9903\n",
      "Epoch 23/49\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9868\n",
      "Epoch 24/49\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9850: 0s - loss: 0.0617 - sparse_categorical_acc\n",
      "Epoch 25/49\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0534 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 26/49\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0586 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 27/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0738 - sparse_categorical_accuracy: 0.9901: 0s - loss: 0.0496 - sparse_categorical_accuracy: 0.99\n",
      "Epoch 28/49\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0384 - sparse_categorical_accuracy: 0.9907\n",
      "Epoch 29/49\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9919\n",
      "Epoch 30/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0234 - sparse_categorical_accuracy: 0.9936: 0s - loss: 0.0171 - sparse_categorical_a\n",
      "Epoch 31/49\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0546 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 32/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0393 - sparse_categorical_accuracy: 0.9927\n",
      "Epoch 33/49\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0578 - sparse_categorical_accuracy: 0.9912: 2s - los\n",
      "Epoch 34/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0472 - sparse_categorical_accuracy: 0.9921\n",
      "Epoch 35/49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9918\n",
      "Epoch 36/49\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9918: 3s \n",
      "Epoch 37/49\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 38/49\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 39/49\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9930: 2s - loss: 0.0110 - \n",
      "Epoch 40/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0396 - sparse_categorical_accuracy: 0.9932\n",
      "Epoch 41/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0547 - sparse_categorical_accuracy: 0.9885\n",
      "Epoch 42/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0849 - sparse_categorical_accuracy: 0.9907A: 4s - loss: 0.0499 - sparse_categorical_accuracy: 0 - ETA: 3s - loss: 0.0372 - sparse_categorical_accuracy - ETA: 2s - loss: 0.0249\n",
      "Epoch 43/49\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.0663 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 44/49\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.0662 - sparse_categorical_accuracy: 0.9901: 2s - loss: 0.0489\n",
      "Epoch 45/49\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 46/49\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9918\n",
      "Epoch 47/49\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.0469 - sparse_categorical_accuracy: 0.9921:\n",
      "Epoch 48/49\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0470 - sparse_categorical_accuracy: 0.9919TA: 3s - loss: 0.0085 - sparse_catego - ETA: 1s - loss: 0.0216 - spars\n",
      "Epoch 49/49\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0460 - sparse_categorical_accuracy: 0.9929\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 5.6296 - sparse_categorical_accuracy: 0.6630\n",
      "lr 0.009000000000000001\n"
     ]
    }
   ],
   "source": [
    "### START CODING HERE ###\n",
    "results2 = []\n",
    "histories2 = []\n",
    "\n",
    "epoch_rates = np.arange(20, 50, 1) \n",
    "for er in epoch_rates: \n",
    "    train_batch = train_tensor.shuffle(len(X_train)).batch(32)\n",
    "    test_batch = test_tensor.shuffle(len(X_test)).batch(32)\n",
    "    model= build_model()\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001) \n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "    nn_clf_historystory2 = model.fit(train_batch, epochs=er)\n",
    "    result2= model.evaluate(test_batch)\n",
    "    print(\"lr\",lr)\n",
    "\n",
    "    results2.append(result2)\n",
    "    histories2.append(nn_clf_historystory2)\n",
    "    \n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6879121,\n",
       " 0.6893773,\n",
       " 0.6754579,\n",
       " 0.6952381,\n",
       " 0.6761905,\n",
       " 0.6666667,\n",
       " 0.6959707,\n",
       " 0.6915751,\n",
       " 0.6908425,\n",
       " 0.6864469,\n",
       " 0.6857143,\n",
       " 0.7054945,\n",
       " 0.6901099,\n",
       " 0.6710623,\n",
       " 0.6747253,\n",
       " 0.6901099,\n",
       " 0.6864469,\n",
       " 0.6901099,\n",
       " 0.6820513,\n",
       " 0.6967033,\n",
       " 0.6864469,\n",
       " 0.6930403,\n",
       " 0.6791209,\n",
       " 0.6783883,\n",
       " 0.6886447,\n",
       " 0.6835165,\n",
       " 0.6930403,\n",
       " 0.6923077,\n",
       " 0.6915751,\n",
       " 0.6630037]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(results))\n",
    "acc2 = [x[1] for x in results2]\n",
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23c9be38e88>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Impact of Epoch Rate on Accuracy')\n",
    "plt.xlabel('epoch_rate', fontsize=14)\n",
    "plt.ylabel('accuracy', fontsize=14)\n",
    "plt.plot(epoch_rates, acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "# Get class probabilities for nn - ignore the warning\n",
    "nn_preds = model.predict(X_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.2986372e-05, 3.2430018e-13, 9.9993706e-01, 6.1710921e-11,\n",
       "       0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See class probabilities predicted by nn classifier\n",
    "nn_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EARLYSTOPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 1.0424 - sparse_categorical_accuracy: 0.5778 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.5594 - sparse_categorical_accuracy: 0.7797 - val_loss: 0.3573 - val_sparse_categorical_accuracy: 0.8685\n",
      "Epoch 3/1000\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4119 - sparse_categorical_accuracy: 0.8341 - val_loss: 0.2935 - val_sparse_categorical_accuracy: 0.8842\n",
      "Epoch 4/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.3298 - sparse_categorical_accuracy: 0.8601 - val_loss: 0.2442 - val_sparse_categorical_accuracy: 0.9040\n",
      "Epoch 5/1000\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2742 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.2067 - val_sparse_categorical_accuracy: 0.9233\n",
      "Epoch 6/1000\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2324 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.1649 - val_sparse_categorical_accuracy: 0.9339\n",
      "Epoch 7/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1758 - sparse_categorical_accuracy: 0.9249 - val_loss: 0.1263 - val_sparse_categorical_accuracy: 0.9476\n",
      "Epoch 8/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.1526 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.1103 - val_sparse_categorical_accuracy: 0.9559\n",
      "Epoch 9/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1250 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.0892 - val_sparse_categorical_accuracy: 0.9667\n",
      "Epoch 10/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1204 - sparse_categorical_accuracy: 0.9560 - val_loss: 0.1265 - val_sparse_categorical_accuracy: 0.9538\n",
      "Epoch 11/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9612 - val_loss: 0.0785 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 12/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9678 - val_loss: 0.0653 - val_sparse_categorical_accuracy: 0.9764\n",
      "Epoch 13/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0801 - sparse_categorical_accuracy: 0.9698 - val_loss: 0.0567 - val_sparse_categorical_accuracy: 0.9797\n",
      "Epoch 14/1000\n",
      "171/171 [==============================] - 3s 16ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.0569 - val_sparse_categorical_accuracy: 0.9804\n",
      "Epoch 15/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0729 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.0440 - val_sparse_categorical_accuracy: 0.9832\n",
      "Epoch 16/1000\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0621 - sparse_categorical_accuracy: 0.9777 - val_loss: 0.0388 - val_sparse_categorical_accuracy: 0.9879\n",
      "Epoch 17/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0692 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0597 - val_sparse_categorical_accuracy: 0.9817\n",
      "Epoch 18/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.0535 - val_sparse_categorical_accuracy: 0.9848\n",
      "Epoch 19/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.0381 - val_sparse_categorical_accuracy: 0.9872\n",
      "Epoch 20/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0552 - sparse_categorical_accuracy: 0.9821 - val_loss: 0.0288 - val_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 21/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0357 - sparse_categorical_accuracy: 0.9861 - val_loss: 0.0251 - val_sparse_categorical_accuracy: 0.9929\n",
      "Epoch 22/1000\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0435 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.0492 - val_sparse_categorical_accuracy: 0.9892\n",
      "Epoch 23/1000\n",
      "171/171 [==============================] - 3s 16ms/step - loss: 0.0636 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0318 - val_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 24/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0631 - sparse_categorical_accuracy: 0.9815 - val_loss: 0.0440 - val_sparse_categorical_accuracy: 0.9846\n",
      "Epoch 25/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0506 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.0476 - val_sparse_categorical_accuracy: 0.9859\n",
      "Epoch 26/1000\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0498 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.0280 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 27/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0311 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.0249 - val_sparse_categorical_accuracy: 0.9918\n",
      "Epoch 28/1000\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.0172 - val_sparse_categorical_accuracy: 0.9943\n",
      "Epoch 29/1000\n",
      "171/171 [==============================] - 3s 16ms/step - loss: 0.0255 - sparse_categorical_accuracy: 0.9921 - val_loss: 0.0194 - val_sparse_categorical_accuracy: 0.9919\n",
      "Epoch 30/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0200 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.0176 - val_sparse_categorical_accuracy: 0.9945\n",
      "Epoch 31/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.0275 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 32/1000\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0208 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0191 - val_sparse_categorical_accuracy: 0.9936\n",
      "Epoch 33/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0277 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0235 - val_sparse_categorical_accuracy: 0.9938ss: 0.0309 - sparse_categorical_accuracy: \n",
      "Epoch 34/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9877 - val_loss: 0.0389 - val_sparse_categorical_accuracy: 0.9874\n",
      "Epoch 35/1000\n",
      "171/171 [==============================] - 3s 16ms/step - loss: 0.0546 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.0393 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 36/1000\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9872 - val_loss: 0.0426 - val_sparse_categorical_accuracy: 0.9897\n",
      "Epoch 37/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0481 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.0245 - val_sparse_categorical_accuracy: 0.9923\n",
      "Epoch 38/1000\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.0422 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.0388 - val_sparse_categorical_accuracy: 0.9921oss: 0.0323 - sparse_categorical_accuracy: - ETA: 0s - loss: 0.0383 - sparse_categorical_accuracy:\n"
     ]
    }
   ],
   "source": [
    "### START CODING HERE ###\n",
    "model = build_model()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy']) \n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit(train_batch, epochs=1000, validation_data=(train_batch), callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 5ms/step - loss: 2.4843 - sparse_categorical_accuracy: 0.6916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4842509724373043, 0.6915751]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning code here\n",
    "\n",
    "# Add more cells when/if necessary for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN 20 EPOCH WITH A TEST SIZE OF 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4777, 1678)\n",
      "(4777,)\n",
      "(2048, 1678)\n",
      "(2048,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data to train and test with test_size=0.33 and random_state=66\n",
    "### START CODING HERE ###\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "### END CODING HERE ###\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data to tf\n",
    "train_tensor = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\n",
    "test_tensor = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [ 0.84612057 -0.11834324 -0.32893862 ... -0.01210455 -0.01711967\n",
      " -0.01210455], Target: 2\n",
      "Features: [-0.10371666 -0.37677181 -0.34348768 ... -0.01210455 -0.01711967\n",
      " -0.01210455], Target: 0\n",
      "Features: [ 0.60866126 -0.30441181 -0.32893862 ... -0.01210455 -0.01711967\n",
      " -0.01210455], Target: 2\n",
      "Features: [ 0.13374265 -0.33542324 -0.34348768 ... -0.01210455 -0.01711967\n",
      " -0.01210455], Target: 1\n",
      "Features: [ 1.32103918  0.85334816  0.44216116 ... -0.01210455 -0.01711967\n",
      " -0.01210455], Target: 3\n"
     ]
    }
   ],
   "source": [
    "for feat, targ in train_tensor.take(5):\n",
    "  print ('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
     ]
    }
   ],
   "source": [
    "# Batch train and test data\n",
    "train_batch = train_tensor.shuffle(len(X_train)).batch(10)\n",
    "test_batch = test_tensor.shuffle(len(X_test)).batch(10)\n",
    "\n",
    "print(type(train_batch))\n",
    "print(type(test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "# Build a Sequential neural network - a classifier model\n",
    "def build_model():\n",
    "    nn_clf = tf.keras.Sequential([\n",
    "        # Create a dense layer with 1000 units, input_dim=1678, and 'relu' activation function ~ 1 line\n",
    "        tf.keras.layers.Dense(1000, input_dim=1678, activation='relu'), \n",
    "        # Create a dense layer with 500 units, and 'relu' activation function \n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(200, activation='relu'), \n",
    "        tf.keras.layers.Dense(70, activation='relu'), \n",
    "        tf.keras.layers.Dense(20, activation='relu'), \n",
    "      \n",
    "        #output layer\n",
    "        tf.keras.layers.Dense(7, activation='softmax')\n",
    "        ])  \n",
    "    return nn_clf\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "# Compile the model \n",
    "model = build_model()\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy']) \n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "478/478 [==============================] - 10s 22ms/step - loss: 1.0886 - sparse_categorical_accuracy: 0.5514\n",
      "Epoch 2/20\n",
      "478/478 [==============================] - 8s 17ms/step - loss: 0.7222 - sparse_categorical_accuracy: 0.7314: 4s - loss: 0.6933 - sparse_categoric - ETA: \n",
      "Epoch 3/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.5920 - sparse_categorical_accuracy: 0.7867: 1s - loss: 0.5661 - sparse_\n",
      "Epoch 4/20\n",
      "478/478 [==============================] - 8s 17ms/step - loss: 0.5137 - sparse_categorical_accuracy: 0.8216\n",
      "Epoch 5/20\n",
      "478/478 [==============================] - 8s 17ms/step - loss: 0.4395 - sparse_categorical_accuracy: 0.8499\n",
      "Epoch 6/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.3907 - sparse_categorical_accuracy: 0.8648\n",
      "Epoch 7/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.3669 - sparse_categorical_accuracy: 0.8861: 6s - loss: 0.3024 \n",
      "Epoch 8/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.2932 - sparse_categorical_accuracy: 0.9027\n",
      "Epoch 9/20\n",
      "478/478 [==============================] - 8s 17ms/step - loss: 0.3257 - sparse_categorical_accuracy: 0.9200: 4s - loss: 0.3766 - s\n",
      "Epoch 10/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.2919 - sparse_categorical_accuracy: 0.9230: 6s - loss: 0.2330 - sparse_ca\n",
      "Epoch 11/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.2750 - sparse_categorical_accuracy: 0.9364\n",
      "Epoch 12/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.2083 - sparse_categorical_accuracy: 0.9479: 3s \n",
      "Epoch 13/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.2297 - sparse_categorical_accuracy: 0.9529: 6s - loss: 0.2188 - ETA: 4s - loss: 0.1849 - sparse_categorical_accuracy: 0 - ETA: 4s - loss: 0.1763 - sparse_cat - ETA: 2s - lo\n",
      "Epoch 14/20\n",
      "478/478 [==============================] - 8s 17ms/step - loss: 0.1646 - sparse_categorical_accuracy: 0.9598\n",
      "Epoch 15/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.2203 - sparse_categorical_accuracy: 0.9592: 6s - loss: 0\n",
      "Epoch 16/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.2236 - sparse_categorical_accuracy: 0.9642\n",
      "Epoch 17/20\n",
      "478/478 [==============================] - 8s 17ms/step - loss: 0.1849 - sparse_categorical_accuracy: 0.9667: 1s - loss: 0.1802 - sparse_categ\n",
      "Epoch 18/20\n",
      "478/478 [==============================] - 8s 17ms/step - loss: 0.1735 - sparse_categorical_accuracy: 0.9669\n",
      "Epoch 19/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.1810 - sparse_categorical_accuracy: 0.9724: 3s  - ETA: 0s - loss: 0.1584 - sparse_categorical_accu\n",
      "Epoch 20/20\n",
      "478/478 [==============================] - 8s 16ms/step - loss: 0.2237 - sparse_categorical_accuracy: 0.9705: 6s - loss: 0.0380 - sparse_ca - ETA: 5s - loss: 0.2051 - sp - ETA: 3s - loss: 0.1772 - sparse_c - ETA: 2s - loss: 0.1725 - sparse_categorical_a - ETA: 1s - loss: 0.1986 - sparse_categorica\n"
     ]
    }
   ],
   "source": [
    " nn_clf_historystory = model.fit(train_batch, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 1s 6ms/step - loss: 7.1076 - sparse_categorical_accuracy: 0.6997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.107590169960451, 0.69970703]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START CODING HERE ###\n",
    "# evaluate nn_clf model on test_batch using .evaluate method\n",
    "model.evaluate(test_batch)\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your results must include at least one comparison table and two plots (for groups 4 plots required)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should compare all of the methods in one or multiple tables, showing clearly the method names, the metrics used for comparison and the results (accuracy, scores, loss, etc). You may use [online tools such as this](https://www.tablesgenerator.com/markdown_tables) for generating and editing neatly-formatted tables in Markdown. You can then copy the code to your Markdown cell to generate the plot. Groups should add more rows/columns as required.\n",
    "<br>\n",
    "\n",
    "<b>Notice: </b>You should use at least two different metrics for comparison of your methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your comparison table HERE:<br><br>\n",
    "\n",
    "| Metric/Method                    | Method 1 Random Forest| Method 2 MLP| Method 3 Neural Network|\n",
    "|:----------------------------------:|:---------------------:|:-----------:|:----------------------:|\n",
    "|Metric 1 Accuracy                   |           49%         |    64%      |        67-69%          |\n",
    "|Metric 2 Percision Weighted Average |           70%         |    80%      |         71%            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using meaningful plots is an efficient way to visualize and conlude your experiments as well as results. Examples of acceptable plots include but are not limited to:\n",
    "- ROC curve (can be used with classification only)\n",
    "- loss plots (precision/recall for classification, mse or mae for regression)\n",
    "- hyperparameter tuning plots (varying one hyperparameter using for loops on x-axis and accuracy/loss on y-axis)\n",
    "- train/validation/test errors/loss plots, histogram of errors and so on.\n",
    "\n",
    "<b>Notice:</b> All plots should have title, xlabel, ylabel, and (if applicable) legend. Use different colors if you have multiple curves on one plot. Points will be deducted if your plots are incomplete. Check matplotlib documentation, examples from the assignments, and research papers or ML articles and find those plots that are applicable to your project. Individual students should have at least 2 plots while groups should have at least 4 plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding - Groups should add more cell as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEE ABOVE FOR PLOTS AND PLOT CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot-1 code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot-2 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write at least two paragraphs to describe and discuss your results. Make arguments based on your observations and results. Use reasoning and analytical thinking for your discussion.\n",
    "\n",
    "Of the two sklearn models I chose, MLPClassifier with an accuracy of 63% performed better than Random Forest Classifier that had an accuracy of 49%.  The tensorflow method performed the best of the three methods.  I ran it about four times.  It usually gave about a 68-69% accuracy which is pretty good.  I also tried the four different activation functions for the MLPClassifier and they all gave about the same accuracy except for the logistic activation which gave the lowest accuaracy at about 40%.  I tried changing many hyperperameters for the Random Forest Calssifier, but for whatever I changed, the accuracy only increased or decreased by about 1-2%.  I changed the number of hidden layers for the neural network as well as the final amount.  The current layers appeared to have the best result.\n",
    " \n",
    "There are two for-loops that were created to check the learning rate accuracy and the epoch accuracy.  From the graph for the learning rate accuracy we can see that as the learning rate increases, the accuracy decreases.  There is a slight increase in accuracy at around 0.006 learning rate, but that still is not as good as the initial learning rate of 0.001 which gave the best accuracy.  As a result of this, I set the learning rate for the other neural networks at 0.001 as well.  For the epoch graph, it seems pretty random, but it also appears that the better accuracy is at about 30 epochs.  However, that is not always guaranteed.  I also changed the test size from 0.20 to 0.33.  I ran it for 30 epochs and got a 69% accuracy.  That may indicate that the larger a test size is, the greater the accuracy.  The precision weighted average of all of the methods was especially good.  This may be because three of the outputs are only in the file a few times, so the accuracy went down.  It is somewhat surprising that the overall best accuracy was the neural network, but it had the second to best percision weighted accuracy of the three.  The Random Forest Classifier had a 100% accuracy for the second output, which is very good considering it performed the worst of the three classifiers.   \n",
    "\n",
    "<b>Notice:</b> Having a thorough discussion is VERY important and has a significant impact on your final score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project grading rubric (total 100 points - 20% of the final grade):\n",
    "\n",
    "- Project proposal: 10 points\n",
    "\n",
    "- Final submission: 70 points - Breakdown as follows\n",
    "\n",
    "    - 30 points: Methods, hyperparameter tuning and comparison table\n",
    "    \n",
    "    - 20 points: Plots\n",
    "\n",
    "    - 20 points: Discussion (2 paragraphs)\n",
    "    \n",
    "- Project complexity and intellectual efforts judged by the instructor: 20 points\n",
    "    \n",
    "<b>Notice:</b> similar to the assignments, up to 10 points may be deducted if your notebook is not easy to read and/or has spelling/grammatical errors, so proofread your notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Submit and Due Date - Late Penalty Will be Strictly Applied!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your final project notebook ```Lastname-Project.ipynb```. Submit the notebook file with your dataset file in a zip file named EXACTLY as `Lastname-Project.zip` using the ```Final Project``` link on Blackboard. For groups, only one submission is required.\n",
    "\n",
    "<font color=red><b>Project Final Submission Due Date: Monday Dec 9th 11:59PM.</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
